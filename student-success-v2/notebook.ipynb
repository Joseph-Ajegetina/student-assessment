{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21cbd657-ff64-406b-a95c-d94c5fe9c59d",
   "metadata": {},
   "source": [
    "<a id='1-problem-framing'></a>\n",
    "## 1. Problem Framing and Research Questions\n",
    "\n",
    "### Context\n",
    "Ashesi University seeks to understand patterns in student success from admissions through graduation. The goal is NOT to create deterministic predictions that label students, but rather to:\n",
    "\n",
    "1. **Identify students who may benefit from early support**\n",
    "2. **Understand factors that correlate with academic success**\n",
    "3. **Evaluate whether certain academic pathways lead to different outcomes**\n",
    "\n",
    "### Ethical Framework\n",
    "Before proceeding, we establish key ethical principles:\n",
    "\n",
    "- **Fairness**: Models should not discriminate based on protected characteristics\n",
    "- **Transparency**: All predictions should be explainable\n",
    "- **Human-in-the-loop**: Predictions are tools for advisors, not final decisions\n",
    "- **Privacy**: Student data must be handled with confidentiality\n",
    "- **Non-determinism**: Students can always change their trajectory\n",
    "\n",
    "### Research Questions Addressed\n",
    "\n",
    "| # | Question | Target Variable | Input Data |\n",
    "|---|----------|-----------------|------------|\n",
    "| 1 | Predict first-year academic struggles | First-year GPA < 2.0 | Admissions data |\n",
    "| 2 | Patterns predicting AJC cases | AJC case occurrence/verdict | Admissions data |\n",
    "| 3 | Success in chosen major | Final CGPA | Admissions + Year 1 data |\n",
    "| 4 | Major change/failure prediction | Program change | Admissions + Year 1 data |\n",
    "| 5 | Math track outcomes | Graduation GPA | Math track placement |\n",
    "| 6 | Extended graduation time | Semesters > 8 | Admissions + Year 1-2 data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cebbd23b-8cdf-4499-a0ed-8d6074a423f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ashesi Student Success Prediction Pipeline\n",
    "Updated based on actual data samples\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create necessary directories\n",
    "DIRECTORIES = [\n",
    "    'data/raw', 'data/processed', 'data/features',\n",
    "    'models', 'reports/figures', 'reports', 'logs'\n",
    "]\n",
    "for directory in DIRECTORIES:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24f37a-7c56-48bf-a074-84a1da3236bd",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8b428c-5cf4-41f1-9a34-d92dd925dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"Load all datasets with proper handling\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path='data/raw/'):\n",
    "        self.data_path = data_path\n",
    "        self.datasets = {}\n",
    "        \n",
    "    def load_all_datasets(self):\n",
    "        \"\"\"Load all datasets from CSV files\"\"\"\n",
    "        \n",
    "        print(\"  Loading datasets...\")\n",
    "        \n",
    "        # Define all expected files\n",
    "        files = {\n",
    "            'application': 'application.csv',\n",
    "            'cgpa': 'cgpa.csv',\n",
    "            'ajc': 'ajc.csv',\n",
    "            'wasce': 'wasce.csv',\n",
    "            'oa_level': 'oa_level.csv',\n",
    "            'hsdiploma': 'hsdiploma.csv',\n",
    "            'french': 'french.csv',\n",
    "            'ib': 'ib.csv',\n",
    "            'other': 'other.csv'\n",
    "        }\n",
    "        \n",
    "        for name, filename in files.items():\n",
    "            filepath = os.path.join(self.data_path, filename)\n",
    "            if os.path.exists(filepath):\n",
    "                try:\n",
    "                    self.datasets[name] = pd.read_csv(filepath, low_memory=False)\n",
    "                    print(f\"    ✓ Loaded {name}: {len(self.datasets[name])} rows, {len(self.datasets[name].columns)} cols\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    ✗ Error loading {name}: {e}\")\n",
    "            else:\n",
    "                print(f\"    ✗ File not found: {filepath}\")\n",
    "        \n",
    "        return self.datasets\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get summary of loaded datasets\"\"\"\n",
    "        summary = []\n",
    "        for name, df in self.datasets.items():\n",
    "            summary.append({\n",
    "                'Dataset': name,\n",
    "                'Rows': len(df),\n",
    "                'Columns': len(df.columns),\n",
    "                'Missing %': round((df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100, 1)\n",
    "            })\n",
    "        return pd.DataFrame(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e6aa469-51cd-46f8-b9f3-9fd4cc37306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PHASE 1] DATA LOADING\n",
      "--------------------------------------------------\n",
      "  Loading datasets...\n",
      "    ✓ Loaded application: 12647 rows, 37 cols\n",
      "    ✓ Loaded cgpa: 24648 rows, 12 cols\n",
      "    ✓ Loaded ajc: 143 rows, 8 cols\n",
      "    ✓ Loaded wasce: 1274 rows, 71 cols\n",
      "    ✓ Loaded oa_level: 343 rows, 150 cols\n",
      "    ✓ Loaded hsdiploma: 51 rows, 118 cols\n",
      "    ✓ Loaded french: 23 rows, 107 cols\n",
      "    ✓ Loaded ib: 131 rows, 115 cols\n",
      "    ✓ Loaded other: 141 rows, 75 cols\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[PHASE 1] DATA LOADING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "loader = DataLoader()\n",
    "datasets = loader.load_all_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb7ab5-5b00-40bf-b2a5-13afe98f9fe1",
   "metadata": {},
   "source": [
    "#### Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c8d3551-b8a8-4d0f-806a-67266ff7a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIntegrator:\n",
    "    \"\"\"Integrate all datasets with proper ID standardization\"\"\"\n",
    "    \n",
    "    def __init__(self, datasets):\n",
    "        self.datasets = datasets\n",
    "        self.master_df = None\n",
    "        self.high_school_combined = None\n",
    "        self.semester_records = None\n",
    "        \n",
    "    def standardize_student_ids(self):\n",
    "        \"\"\"Standardize student ID column names\"\"\"\n",
    "        \n",
    "        print(\"  Standardizing student IDs...\")\n",
    "        \n",
    "        # Map of dataset name to ID column name\n",
    "        id_mappings = {\n",
    "            'application': 'StudentRef',\n",
    "            'cgpa': 'StudentRef',  # Note: Sample showed 'StudentRef', not 'Student Ref'\n",
    "            'ajc': 'StudentRef',\n",
    "            'wasce': 'StudentRef',\n",
    "            'oa_level': 'StudentRef',\n",
    "            'hsdiploma': 'StudentRef',\n",
    "            'french': 'StudentRef',\n",
    "            'ib': 'StudentRef',\n",
    "            'other': 'StudentRef'\n",
    "        }\n",
    "        \n",
    "        for dataset_name, id_col in id_mappings.items():\n",
    "            if dataset_name in self.datasets:\n",
    "                df = self.datasets[dataset_name]\n",
    "                \n",
    "                # Find the ID column (handle variations)\n",
    "                possible_cols = ['StudentRef', 'Student Ref', 'studentref', 'student_ref']\n",
    "                found_col = None\n",
    "                for col in possible_cols:\n",
    "                    if col in df.columns:\n",
    "                        found_col = col\n",
    "                        break\n",
    "                \n",
    "                if found_col:\n",
    "                    df = df.rename(columns={found_col: 'student_id'})\n",
    "                    df['student_id'] = df['student_id'].astype(str).str.strip()\n",
    "                    self.datasets[dataset_name] = df\n",
    "                    \n",
    "        return self.datasets\n",
    "    \n",
    "    def combine_high_school_exams(self):\n",
    "        \"\"\"Combine all high school exam datasets with proper grade handling\"\"\"\n",
    "        \n",
    "        print(\"  Combining high school exam data...\")\n",
    "        \n",
    "        exam_datasets = ['wasce', 'oa_level', 'hsdiploma', 'french', 'ib', 'other']\n",
    "        combined_records = []\n",
    "        \n",
    "        for exam_name in exam_datasets:\n",
    "            if exam_name not in self.datasets:\n",
    "                continue\n",
    "                \n",
    "            df = self.datasets[exam_name].copy()\n",
    "            \n",
    "            # Extract key information\n",
    "            record = {\n",
    "                'student_id': df.get('student_id', df.get('StudentRef')),\n",
    "                'yeargroup': df.get('Yeargroup'),\n",
    "                'proposed_major': df.get('Proposed Major'),\n",
    "                'high_school': df.get('High School'),\n",
    "                'exam_type': df.get('Exam Type'),\n",
    "                'exam_year': df.get('Exam Year'),\n",
    "                'exam_source': exam_name\n",
    "            }\n",
    "            \n",
    "            # Extract and standardize scores based on exam type\n",
    "            if exam_name == 'wasce':\n",
    "                record['total_score'] = df.get('Total Aggregate')\n",
    "                record['math_score'] = self._convert_wassce_grade(df.get('Mathematics'))\n",
    "                record['english_score'] = self._convert_wassce_grade(df.get('English Language'))\n",
    "                record['science_score'] = self._convert_wassce_grade(df.get('Integrated Science'))\n",
    "                \n",
    "            elif exam_name == 'ib':\n",
    "                record['total_score'] = df.get('Points')\n",
    "                record['math_score'] = df.get('Maths (SL)', df.get('Mathematics SL in English'))\n",
    "                record['english_score'] = df.get('English A: Literature HL', df.get('English A: Lang & Lit. SL'))\n",
    "                \n",
    "            elif exam_name == 'french':\n",
    "                # Parse French Bac scores (e.g., \"14.15/20\")\n",
    "                record['total_score'] = df.get('Points').apply(self._parse_french_score) if 'Points' in df.columns else None\n",
    "                record['math_score'] = df.get('Mathematics').apply(self._parse_french_subject_score) if 'Mathematics' in df.columns else None\n",
    "                \n",
    "            else:\n",
    "                # Generic handling for other exam types\n",
    "                record['total_score'] = df.get('Points')\n",
    "                record['math_score'] = df.get('Mathematics', df.get('Maths'))\n",
    "                record['english_score'] = df.get('English', df.get('English Language'))\n",
    "            \n",
    "            # Create DataFrame from this exam type\n",
    "            exam_df = pd.DataFrame(record)\n",
    "            exam_df['exam_source'] = exam_name\n",
    "            combined_records.append(exam_df)\n",
    "        \n",
    "        if combined_records:\n",
    "            self.high_school_combined = pd.concat(combined_records, ignore_index=True)\n",
    "            print(f\"    ✓ Combined {len(self.high_school_combined)} exam records from {len(combined_records)} sources\")\n",
    "        else:\n",
    "            self.high_school_combined = pd.DataFrame()\n",
    "            \n",
    "        return self.high_school_combined\n",
    "    \n",
    "    def _convert_wassce_grade(self, series):\n",
    "        \"\"\"Convert WASSCE grades (A1-F9) to numeric scores\"\"\"\n",
    "        if series is None:\n",
    "            return None\n",
    "            \n",
    "        grade_map = {\n",
    "            'A1': 1, 'B2': 2, 'B3': 3, 'C4': 4, 'C5': 5,\n",
    "            'C6': 6, 'D7': 7, 'E8': 8, 'F9': 9\n",
    "        }\n",
    "        \n",
    "        if isinstance(series, pd.Series):\n",
    "            return series.map(grade_map)\n",
    "        else:\n",
    "            return grade_map.get(series)\n",
    "    \n",
    "    def _parse_french_score(self, score_str):\n",
    "        \"\"\"Parse French Bac score format (e.g., '14.15/20')\"\"\"\n",
    "        if pd.isna(score_str):\n",
    "            return np.nan\n",
    "        \n",
    "        score_str = str(score_str)\n",
    "        match = re.match(r'([\\d.]+)/(\\d+)', score_str)\n",
    "        if match:\n",
    "            score = float(match.group(1))\n",
    "            max_score = float(match.group(2))\n",
    "            # Normalize to percentage\n",
    "            return (score / max_score) * 100\n",
    "        \n",
    "        try:\n",
    "            return float(score_str)\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    def _parse_french_subject_score(self, score_str):\n",
    "        \"\"\"Parse French subject scores (various formats)\"\"\"\n",
    "        if pd.isna(score_str):\n",
    "            return np.nan\n",
    "        \n",
    "        score_str = str(score_str)\n",
    "        \n",
    "        # Handle \"35/100\" format\n",
    "        match = re.match(r'([\\d.]+)/(\\d+)', score_str)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "        \n",
    "        try:\n",
    "            return float(score_str)\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    def create_semester_records(self):\n",
    "        \"\"\"Create longitudinal semester records from CGPA data\"\"\"\n",
    "        \n",
    "        print(\"  Creating semester records...\")\n",
    "        \n",
    "        if 'cgpa' not in self.datasets:\n",
    "            print(\"    ✗ CGPA data not available\")\n",
    "            return None\n",
    "            \n",
    "        cgpa = self.datasets['cgpa'].copy()\n",
    "        \n",
    "        # Parse semester information from 'Semester/Year' column\n",
    "        # Format: \"Semester 1\", \"Semester 2\"\n",
    "        if 'Semester/Year' in cgpa.columns:\n",
    "            cgpa['semester_num'] = cgpa['Semester/Year'].str.extract(r'Semester (\\d)').astype(float)\n",
    "        \n",
    "        # Calculate year number from Academic Year and Admission Year\n",
    "        # Academic Year format: \"2015-2016\", Admission Year format: \"2013-2014\"\n",
    "        if 'Academic Year' in cgpa.columns and 'Admission Year' in cgpa.columns:\n",
    "            def extract_start_year(year_str):\n",
    "                if pd.isna(year_str):\n",
    "                    return np.nan\n",
    "                match = re.match(r'(\\d{4})', str(year_str))\n",
    "                return int(match.group(1)) if match else np.nan\n",
    "            \n",
    "            cgpa['academic_start_year'] = cgpa['Academic Year'].apply(extract_start_year)\n",
    "            cgpa['admission_start_year'] = cgpa['Admission Year'].apply(extract_start_year)\n",
    "            cgpa['year_num'] = cgpa['academic_start_year'] - cgpa['admission_start_year'] + 1\n",
    "        \n",
    "        # Create semester order (for sorting and trajectory analysis)\n",
    "        if 'year_num' in cgpa.columns and 'semester_num' in cgpa.columns:\n",
    "            cgpa['semester_order'] = (cgpa['year_num'] - 1) * 2 + cgpa['semester_num']\n",
    "        \n",
    "        # Sort by student and semester\n",
    "        sort_cols = ['student_id']\n",
    "        if 'semester_order' in cgpa.columns:\n",
    "            sort_cols.append('semester_order')\n",
    "        cgpa = cgpa.sort_values(sort_cols)\n",
    "        \n",
    "        # Calculate performance indicators\n",
    "        if 'GPA' in cgpa.columns:\n",
    "            cgpa['gpa_change'] = cgpa.groupby('student_id')['GPA'].diff()\n",
    "        \n",
    "        if 'CGPA' in cgpa.columns:\n",
    "            cgpa['on_probation'] = (cgpa['CGPA'] < 2.0).astype(int)\n",
    "            cgpa['deans_list'] = (cgpa['GPA'] >= 3.5).astype(int) if 'GPA' in cgpa.columns else 0\n",
    "        \n",
    "        # Identify consecutive probation (dismissal risk)\n",
    "        if 'on_probation' in cgpa.columns:\n",
    "            def check_consecutive_probation(group):\n",
    "                group = group.sort_values('semester_order') if 'semester_order' in group.columns else group\n",
    "                group['consecutive_probation'] = (\n",
    "                    (group['on_probation'] == 1) & \n",
    "                    (group['on_probation'].shift(1) == 1)\n",
    "                )\n",
    "                return group\n",
    "            \n",
    "            cgpa = cgpa.groupby('student_id', group_keys=False).apply(check_consecutive_probation)\n",
    "        \n",
    "        self.semester_records = cgpa\n",
    "        print(f\"    ✓ Created {len(self.semester_records)} semester records\")\n",
    "        \n",
    "        return cgpa\n",
    "    \n",
    "    def create_master_table(self):\n",
    "        \"\"\"Create master student table with all features\"\"\"\n",
    "        \n",
    "        print(\"  Creating master student table...\")\n",
    "        \n",
    "        if 'application' not in self.datasets:\n",
    "            print(\"    ✗ Application data not available\")\n",
    "            return None\n",
    "        \n",
    "        # Start with application data\n",
    "        master = self.datasets['application'].copy()\n",
    "        \n",
    "        # === Merge High School Scores ===\n",
    "        if self.high_school_combined is not None and len(self.high_school_combined) > 0:\n",
    "            # Aggregate to one row per student (take first/best scores)\n",
    "            hs_agg = self.high_school_combined.groupby('student_id').agg({\n",
    "                'total_score': 'first',\n",
    "                'math_score': 'first',\n",
    "                'english_score': 'first',\n",
    "                'science_score': 'first' if 'science_score' in self.high_school_combined.columns else 'first',\n",
    "                'exam_type': 'first',\n",
    "                'exam_source': 'first',\n",
    "                'high_school': 'first'\n",
    "            }).reset_index()\n",
    "            \n",
    "            master = master.merge(hs_agg, on='student_id', how='left')\n",
    "        \n",
    "        # === Merge AJC Information ===\n",
    "        if 'ajc' in self.datasets:\n",
    "            ajc = self.datasets['ajc'].copy()\n",
    "            \n",
    "            ajc_agg = ajc.groupby('student_id').agg({\n",
    "                'Type of Misconduct': 'count',\n",
    "                'Verdict': lambda x: (x == 'Guilty').sum()\n",
    "            }).reset_index()\n",
    "            ajc_agg.columns = ['student_id', 'ajc_cases_total', 'ajc_guilty_count']\n",
    "            \n",
    "            master = master.merge(ajc_agg, on='student_id', how='left')\n",
    "            master['ajc_cases_total'] = master['ajc_cases_total'].fillna(0)\n",
    "            master['ajc_guilty_count'] = master['ajc_guilty_count'].fillna(0)\n",
    "            master['has_ajc_case'] = (master['ajc_cases_total'] > 0).astype(int)\n",
    "        \n",
    "        # === Merge CGPA/Performance Data ===\n",
    "        if self.semester_records is not None and len(self.semester_records) > 0:\n",
    "            # Get final performance metrics per student\n",
    "            perf_agg = self.semester_records.groupby('student_id').agg({\n",
    "                'CGPA': 'last',\n",
    "                'GPA': ['mean', 'std', 'min', 'max'],\n",
    "                'Program': 'last',\n",
    "                'Student Status': 'last',\n",
    "                'Yeargroup': 'first',\n",
    "                'on_probation': 'sum' if 'on_probation' in self.semester_records.columns else 'first',\n",
    "                'deans_list': 'sum' if 'deans_list' in self.semester_records.columns else 'first',\n",
    "                'semester_order': 'max'\n",
    "            })\n",
    "            \n",
    "            # Flatten column names\n",
    "            perf_agg.columns = ['_'.join(col).strip('_') if isinstance(col, tuple) else col \n",
    "                               for col in perf_agg.columns]\n",
    "            perf_agg = perf_agg.reset_index()\n",
    "            \n",
    "            # Rename for clarity\n",
    "            perf_agg = perf_agg.rename(columns={\n",
    "                'CGPA_last': 'final_cgpa',\n",
    "                'CGPA': 'final_cgpa',\n",
    "                'GPA_mean': 'avg_gpa',\n",
    "                'GPA_std': 'gpa_std',\n",
    "                'GPA_min': 'min_gpa',\n",
    "                'GPA_max': 'max_gpa',\n",
    "                'Program_last': 'final_program',\n",
    "                'Program': 'final_program',\n",
    "                'Student Status_last': 'student_status',\n",
    "                'Student Status': 'student_status',\n",
    "                'Yeargroup_first': 'yeargroup',\n",
    "                'Yeargroup': 'yeargroup',\n",
    "                'on_probation_sum': 'probation_count',\n",
    "                'on_probation': 'probation_count',\n",
    "                'deans_list_sum': 'deans_list_count',\n",
    "                'deans_list': 'deans_list_count',\n",
    "                'semester_order_max': 'total_semesters',\n",
    "                'semester_order': 'total_semesters'\n",
    "            })\n",
    "            \n",
    "            master = master.merge(perf_agg, on='student_id', how='left')\n",
    "        \n",
    "        # === Get Math Placement from WASCE data ===\n",
    "        if 'wasce' in self.datasets:\n",
    "            wasce = self.datasets['wasce']\n",
    "            math_placement_cols = ['Auto WASSCE Ashesi Math Placement', 'Ashesi Actual Math Placement']\n",
    "            \n",
    "            for col in math_placement_cols:\n",
    "                if col in wasce.columns:\n",
    "                    placement = wasce[['student_id', col]].dropna()\n",
    "                    placement = placement.rename(columns={col: 'math_track'})\n",
    "                    master = master.merge(placement, on='student_id', how='left')\n",
    "                    break\n",
    "        \n",
    "        self.master_df = master\n",
    "        print(f\"    ✓ Created master table: {len(master)} students, {len(master.columns)} features\")\n",
    "        \n",
    "        return master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab370fba-4e64-4ba8-88ba-6eace0ff1b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Standardizing student IDs...\n",
      "  Combining high school exam data...\n",
      "    ✓ Combined 1963 exam records from 6 sources\n",
      "  Creating semester records...\n",
      "    ✓ Created 24648 semester records\n",
      "  Creating master student table...\n",
      "    ✓ Created master table: 12647 students, 59 features\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (178344064.py, line 10)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn None\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "integrator = DataIntegrator(datasets)\n",
    "integrator.standardize_student_ids()\n",
    "integrator.combine_high_school_exams()\n",
    "integrator.create_semester_records()\n",
    "master_df = integrator.create_master_table()\n",
    "semester_records = integrator.semester_records\n",
    "\n",
    "if master_df is None or len(master_df) == 0:\n",
    "    print(\"ERROR: Failed to create master table!\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59253ca-1f90-4301-8132-34b965cf9184",
   "metadata": {},
   "source": [
    "#### 3 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d03399e-12f8-4645-b6dc-cbc9395426f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    \"\"\"Clean and prepare data for analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, master_df, semester_records):\n",
    "        self.master_df = master_df.copy() if master_df is not None else pd.DataFrame()\n",
    "        self.semester_records = semester_records.copy() if semester_records is not None else pd.DataFrame()\n",
    "        \n",
    "    def clean_all(self):\n",
    "        \"\"\"Run all cleaning steps\"\"\"\n",
    "        \n",
    "        if len(self.master_df) == 0:\n",
    "            return self.master_df, self.semester_records\n",
    "            \n",
    "        print(\"  Cleaning data...\")\n",
    "        \n",
    "        self._clean_dates()\n",
    "        self._clean_categorical()\n",
    "        self._clean_numeric()\n",
    "        self._handle_missing()\n",
    "        \n",
    "        print(f\"    ✓ Cleaning complete\")\n",
    "        \n",
    "        return self.master_df, self.semester_records\n",
    "    \n",
    "    def _clean_dates(self):\n",
    "        \"\"\"Parse and clean date columns\"\"\"\n",
    "        \n",
    "        # Application dates (format: \"15/01/2018 5:20\")\n",
    "        date_cols = ['Created date', 'Submitted date']\n",
    "        \n",
    "        for col in date_cols:\n",
    "            if col in self.master_df.columns:\n",
    "                self.master_df[col] = pd.to_datetime(\n",
    "                    self.master_df[col], \n",
    "                    format='%d/%m/%Y %H:%M',\n",
    "                    errors='coerce'\n",
    "                )\n",
    "                # Extract useful features\n",
    "                self.master_df[f'{col}_year'] = self.master_df[col].dt.year\n",
    "                self.master_df[f'{col}_month'] = self.master_df[col].dt.month\n",
    "    \n",
    "    def _clean_categorical(self):\n",
    "        \"\"\"Standardize categorical variables\"\"\"\n",
    "        \n",
    "        # Gender\n",
    "        if 'Gender' in self.master_df.columns:\n",
    "            gender_map = {\n",
    "                'M': 'Male', 'F': 'Female', \n",
    "                'Male': 'Male', 'Female': 'Female',\n",
    "                'm': 'Male', 'f': 'Female'\n",
    "            }\n",
    "            self.master_df['Gender'] = self.master_df['Gender'].map(gender_map).fillna('Unknown')\n",
    "        \n",
    "        # Offer type (admission status)\n",
    "        if 'Offer type' in self.master_df.columns:\n",
    "            self.master_df['was_admitted'] = (\n",
    "                ~self.master_df['Offer type'].isin(['Failed', 'Rejected', 'Declined'])\n",
    "            ).astype(int)\n",
    "        \n",
    "        # Program/Major standardization\n",
    "        program_cols = ['Offer course name', 'final_program', 'Program']\n",
    "        for col in program_cols:\n",
    "            if col in self.master_df.columns:\n",
    "                self.master_df[col] = self.master_df[col].astype(str).str.strip()\n",
    "                # Remove [B.Sc.] prefix\n",
    "                self.master_df[col] = self.master_df[col].str.replace(r'\\[B\\.Sc\\.\\]\\s*', '', regex=True)\n",
    "        \n",
    "        # Nationality regions\n",
    "        if 'Nationality' in self.master_df.columns:\n",
    "            # Since data is anonymized as Country0, Country1, etc., we'll keep as-is\n",
    "            # In real scenario, we'd map to regions\n",
    "            self.master_df['nationality_region'] = self.master_df['Nationality']\n",
    "    \n",
    "    def _clean_numeric(self):\n",
    "        \"\"\"Clean numeric columns\"\"\"\n",
    "        \n",
    "        # CGPA/GPA should be 0-4\n",
    "        gpa_cols = [col for col in self.master_df.columns \n",
    "                   if 'cgpa' in col.lower() or 'gpa' in col.lower()]\n",
    "        \n",
    "        for col in gpa_cols:\n",
    "            if col in self.master_df.columns:\n",
    "                self.master_df[col] = pd.to_numeric(self.master_df[col], errors='coerce')\n",
    "                self.master_df[col] = self.master_df[col].clip(0, 4)\n",
    "        \n",
    "        # Total semesters should be reasonable (1-16)\n",
    "        if 'total_semesters' in self.master_df.columns:\n",
    "            self.master_df['total_semesters'] = self.master_df['total_semesters'].clip(1, 16)\n",
    "    \n",
    "    def _handle_missing(self):\n",
    "        \"\"\"Handle missing values\"\"\"\n",
    "        \n",
    "        # Fill numeric with median\n",
    "        numeric_cols = self.master_df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            if self.master_df[col].isnull().any():\n",
    "                self.master_df[col] = self.master_df[col].fillna(self.master_df[col].median())\n",
    "        \n",
    "        # Fill categorical with 'Unknown'\n",
    "        cat_cols = self.master_df.select_dtypes(include=['object']).columns\n",
    "        for col in cat_cols:\n",
    "            self.master_df[col] = self.master_df[col].fillna('Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f948a20-14c8-4275-9d21-91e7d16f9796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PHASE 3] DATA CLEANING\n",
      "--------------------------------------------------\n",
      "  Cleaning data...\n",
      "    ✓ Cleaning complete\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[PHASE 3] DATA CLEANING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "cleaner = DataCleaner(master_df, semester_records)\n",
    "master_df, semester_records = cleaner.clean_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4332519-cdd1-4bbc-a118-481cd039d366",
   "metadata": {},
   "source": [
    "#### Score Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e10a1ca-014c-4fc0-8d5c-cbdc1c3f137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreStandardizer:\n",
    "    \"\"\"Standardize scores across different exam systems\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define grading scales\n",
    "        self.grade_scales = {\n",
    "            'wassce': {'A1': 1, 'B2': 2, 'B3': 3, 'C4': 4, 'C5': 5, 'C6': 6, 'D7': 7, 'E8': 8, 'F9': 9},\n",
    "            'letter_plus_minus': {'A+': 12, 'A': 11, 'A-': 10, 'B+': 9, 'B': 8, 'B-': 7, \n",
    "                                  'C+': 6, 'C': 5, 'C-': 4, 'D+': 3, 'D': 2, 'D-': 1, 'F': 0},\n",
    "            'ib': list(range(1, 8))  # 1-7 scale\n",
    "        }\n",
    "    \n",
    "    def standardize_all_scores(self, df):\n",
    "        \"\"\"Standardize all exam scores to 0-100 percentile scale\"\"\"\n",
    "        \n",
    "        if 'exam_source' not in df.columns:\n",
    "            return df\n",
    "        \n",
    "        df = df.copy()\n",
    "        \n",
    "        def standardize_row(row):\n",
    "            source = row.get('exam_source', '')\n",
    "            total = row.get('total_score')\n",
    "            \n",
    "            if pd.isna(total):\n",
    "                return np.nan\n",
    "            \n",
    "            try:\n",
    "                total = float(str(total).split('/')[0])  # Handle \"14.15/20\" format\n",
    "            except:\n",
    "                return np.nan\n",
    "            \n",
    "            if source == 'wasce':\n",
    "                # WASSCE: Lower is better, typical range 6-54 for 6 subjects\n",
    "                # Best possible: 6 (6 A1s), Worst: 54 (6 F9s)\n",
    "                return max(0, 100 - ((total - 6) / 48) * 100)\n",
    "            \n",
    "            elif source == 'ib':\n",
    "                # IB: 0-45 scale, higher is better\n",
    "                return (total / 45) * 100\n",
    "            \n",
    "            elif source == 'french':\n",
    "                # French Bac: 0-20 scale, higher is better\n",
    "                if total <= 20:\n",
    "                    return (total / 20) * 100\n",
    "                else:\n",
    "                    return min(100, total)  # Already percentage\n",
    "            \n",
    "            elif source in ['oa_level', 'hsdiploma', 'other']:\n",
    "                # Various scales - normalize based on apparent range\n",
    "                if total <= 12:  # Likely letter grade converted\n",
    "                    return (total / 12) * 100\n",
    "                elif total <= 45:  # Likely IB-style\n",
    "                    return (total / 45) * 100\n",
    "                elif total <= 100:  # Likely percentage\n",
    "                    return total\n",
    "                else:\n",
    "                    return min(100, (total / 200) * 100)\n",
    "            \n",
    "            return np.nan\n",
    "        \n",
    "        df['standardized_score'] = df.apply(standardize_row, axis=1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_performance_tiers(self, df, score_col='standardized_score'):\n",
    "        \"\"\"Create performance tier categories\"\"\"\n",
    "        \n",
    "        if score_col not in df.columns:\n",
    "            df['performance_tier'] = 'Unknown'\n",
    "            return df\n",
    "        \n",
    "        def assign_tier(score):\n",
    "            if pd.isna(score):\n",
    "                return 'Unknown'\n",
    "            elif score >= 85:\n",
    "                return 'Excellent'\n",
    "            elif score >= 70:\n",
    "                return 'Good'\n",
    "            elif score >= 55:\n",
    "                return 'Average'\n",
    "            elif score >= 40:\n",
    "                return 'Below Average'\n",
    "            else:\n",
    "                return 'At Risk'\n",
    "        \n",
    "        df['performance_tier'] = df[score_col].apply(assign_tier)\n",
    "        \n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dc39d98-16f2-4a30-b951-8eae32152b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PHASE 4] SCORE STANDARDIZATION\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[PHASE 4] SCORE STANDARDIZATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "standardizer = ScoreStandardizer()\n",
    "master_df = standardizer.standardize_all_scores(master_df)\n",
    "master_df = standardizer.create_performance_tiers(master_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc222c9-9abb-4d4a-ab8e-4b87512ad58b",
   "metadata": {},
   "source": [
    "#### Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c862c816-6acf-42ef-9189-abe8e465ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetCreator:\n",
    "    \"\"\"Create target variables with proper handling of student status\"\"\"\n",
    "    \n",
    "    def __init__(self, master_df, semester_records):\n",
    "        self.master_df = master_df.copy() if master_df is not None else pd.DataFrame()\n",
    "        self.semester_records = semester_records.copy() if semester_records is not None else pd.DataFrame()\n",
    "        self._identify_student_status()\n",
    "    \n",
    "    def _identify_student_status(self):\n",
    "        \"\"\"Identify and flag student status for proper filtering\"\"\"\n",
    "        \n",
    "        print(\"  Identifying student status...\")\n",
    "        \n",
    "        # Find status column\n",
    "        status_col = None\n",
    "        for col in ['student_status', 'Student Status']:\n",
    "            if col in self.master_df.columns:\n",
    "                status_col = col\n",
    "                break\n",
    "        \n",
    "        if status_col:\n",
    "            status = self.master_df[status_col].astype(str).str.lower().str.strip()\n",
    "            \n",
    "            # Create status flags\n",
    "            self.master_df['is_graduated'] = status.str.contains('graduat', na=False)\n",
    "            self.master_df['is_active'] = status.str.contains('active', na=False)\n",
    "            self.master_df['is_withdrawn'] = status.str.contains('withdraw|left|dropped|quit', na=False)\n",
    "            self.master_df['is_dismissed'] = status.str.contains('dismiss|expel|suspend', na=False)\n",
    "            \n",
    "            # Students with known final outcomes (not active)\n",
    "            self.master_df['has_final_outcome'] = ~self.master_df['is_active']\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"    Student Status Distribution:\")\n",
    "            print(f\"      ├─ Graduated:  {self.master_df['is_graduated'].sum():,}\")\n",
    "            print(f\"      ├─ Active:     {self.master_df['is_active'].sum():,}\")\n",
    "            print(f\"      ├─ Withdrawn:  {self.master_df['is_withdrawn'].sum():,}\")\n",
    "            print(f\"      ├─ Dismissed:  {self.master_df['is_dismissed'].sum():,}\")\n",
    "            print(f\"      └─ Other:      {(~(self.master_df['is_graduated'] | self.master_df['is_active'] | self.master_df['is_withdrawn'] | self.master_df['is_dismissed'])).sum():,}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"    ⚠️ Student status column not found - assuming all graduated\")\n",
    "            self.master_df['is_graduated'] = True\n",
    "            self.master_df['is_active'] = False\n",
    "            self.master_df['is_withdrawn'] = False\n",
    "            self.master_df['is_dismissed'] = False\n",
    "            self.master_df['has_final_outcome'] = True\n",
    "    \n",
    "    def create_all_targets(self):\n",
    "        \"\"\"Create all target variables with proper filtering\"\"\"\n",
    "        \n",
    "        if len(self.master_df) == 0:\n",
    "            return self.master_df\n",
    "        \n",
    "        print(\"  Creating target variables...\")\n",
    "        \n",
    "        self._create_first_year_struggle()\n",
    "        self._create_ajc_target()\n",
    "        self._create_major_success()\n",
    "        self._create_extended_graduation()\n",
    "        self._create_completion_target()\n",
    "        self._create_retention_target()\n",
    "        self._create_math_track()\n",
    "        \n",
    "        # Generate validity summary\n",
    "        self._print_target_summary()\n",
    "        \n",
    "        return self.master_df\n",
    "    \n",
    "    def _create_first_year_struggle(self):\n",
    "        \"\"\"\n",
    "        Q1: First year academic struggle\n",
    "        \n",
    "        Valid for: ALL students who completed Year 1 (including active, withdrawn)\n",
    "        Definition: CGPA < 2.0 OR was on probation during Year 1\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get Year 1 data from semester records\n",
    "        if len(self.semester_records) > 0 and 'year_num' in self.semester_records.columns:\n",
    "            y1_data = self.semester_records[self.semester_records['year_num'] == 1]\n",
    "            \n",
    "            if len(y1_data) > 0:\n",
    "                # Aggregate Year 1 performance\n",
    "                agg_dict = {'student_id': 'first'}\n",
    "                \n",
    "                if 'CGPA' in y1_data.columns:\n",
    "                    agg_dict['CGPA'] = 'last'\n",
    "                if 'GPA' in y1_data.columns:\n",
    "                    agg_dict['GPA'] = 'mean'\n",
    "                if 'on_probation' in y1_data.columns:\n",
    "                    agg_dict['on_probation'] = 'max'\n",
    "                \n",
    "                y1_agg = y1_data.groupby('student_id').agg(agg_dict).reset_index(drop=True)\n",
    "                \n",
    "                # Rename columns\n",
    "                col_rename = {\n",
    "                    'CGPA': 'y1_cgpa',\n",
    "                    'GPA': 'y1_avg_gpa',\n",
    "                    'on_probation': 'y1_was_on_probation'\n",
    "                }\n",
    "                y1_agg = y1_agg.rename(columns=col_rename)\n",
    "                \n",
    "                # Merge with master\n",
    "                self.master_df = self.master_df.merge(\n",
    "                    y1_agg, on='student_id', how='left', suffixes=('', '_y1')\n",
    "                )\n",
    "                \n",
    "                # Mark students who completed Year 1\n",
    "                self.master_df['completed_year1'] = self.master_df['y1_cgpa'].notna()\n",
    "        else:\n",
    "            self.master_df['completed_year1'] = False\n",
    "        \n",
    "        # Create target variable\n",
    "        if 'y1_cgpa' in self.master_df.columns:\n",
    "            # Only valid for students who completed Year 1\n",
    "            conditions = [\n",
    "                self.master_df['completed_year1'] == True\n",
    "            ]\n",
    "            \n",
    "            struggle_condition = (\n",
    "                (self.master_df['y1_cgpa'] < 2.0) |\n",
    "                (self.master_df.get('y1_was_on_probation', 0) == 1)\n",
    "            )\n",
    "            \n",
    "            self.master_df['first_year_struggle'] = np.where(\n",
    "                self.master_df['completed_year1'],\n",
    "                struggle_condition.astype(int),\n",
    "                np.nan\n",
    "            )\n",
    "        else:\n",
    "            self.master_df['first_year_struggle'] = np.nan\n",
    "    \n",
    "    def _create_ajc_target(self):\n",
    "        \"\"\"\n",
    "        Q2: AJC case prediction\n",
    "        \n",
    "        Valid for: ALL students (graduated, active, withdrawn, dismissed)\n",
    "        Definition: Had at least one AJC case\n",
    "        \"\"\"\n",
    "        \n",
    "        if 'ajc_cases_total' in self.master_df.columns:\n",
    "            self.master_df['has_ajc_case'] = (\n",
    "                self.master_df['ajc_cases_total'].fillna(0) > 0\n",
    "            ).astype(int)\n",
    "        else:\n",
    "            self.master_df['has_ajc_case'] = 0\n",
    "        \n",
    "        if 'ajc_guilty_count' in self.master_df.columns:\n",
    "            self.master_df['found_guilty'] = (\n",
    "                self.master_df['ajc_guilty_count'].fillna(0) > 0\n",
    "            ).astype(int)\n",
    "        else:\n",
    "            self.master_df['found_guilty'] = 0\n",
    "    \n",
    "    def _create_major_success(self):\n",
    "        \"\"\"\n",
    "        Q3-Q6: Major success/failure\n",
    "        \n",
    "        Valid for: ONLY GRADUATED students (known final outcome)\n",
    "        Definition: \n",
    "            - Success: Final CGPA >= 3.0\n",
    "            - Excellence: Final CGPA >= 3.5\n",
    "            - Struggle: Final CGPA < 2.0 OR was dismissed\n",
    "        \"\"\"\n",
    "        \n",
    "        if 'final_cgpa' not in self.master_df.columns:\n",
    "            self.master_df['major_success'] = np.nan\n",
    "            self.master_df['major_excellence'] = np.nan\n",
    "            self.master_df['major_struggle'] = np.nan\n",
    "            return\n",
    "        \n",
    "        graduated_mask = self.master_df['is_graduated'] == True\n",
    "        dismissed_mask = self.master_df['is_dismissed'] == True\n",
    "        \n",
    "        # Major Success: Graduated with CGPA >= 3.0\n",
    "        self.master_df['major_success'] = np.where(\n",
    "            graduated_mask,\n",
    "            (self.master_df['final_cgpa'] >= 3.0).astype(int),\n",
    "            np.nan\n",
    "        )\n",
    "        \n",
    "        # Major Excellence: Graduated with CGPA >= 3.5 (Dean's List level)\n",
    "        self.master_df['major_excellence'] = np.where(\n",
    "            graduated_mask,\n",
    "            (self.master_df['final_cgpa'] >= 3.5).astype(int),\n",
    "            np.nan\n",
    "        )\n",
    "        \n",
    "        # Major Struggle: Dismissed OR graduated with low CGPA\n",
    "        self.master_df['major_struggle'] = np.where(\n",
    "            graduated_mask | dismissed_mask,\n",
    "            (\n",
    "                dismissed_mask |\n",
    "                ((graduated_mask) & (self.master_df['final_cgpa'] < 2.0))\n",
    "            ).astype(int),\n",
    "            np.nan\n",
    "        )\n",
    "    \n",
    "    def _create_extended_graduation(self):\n",
    "        \"\"\"\n",
    "        Q9: Extended graduation (>8 semesters)\n",
    "        \n",
    "        Valid for: ONLY GRADUATED students\n",
    "        Definition: Took more than 8 semesters (4 years) to graduate\n",
    "        \"\"\"\n",
    "        \n",
    "        if 'total_semesters' not in self.master_df.columns:\n",
    "            self.master_df['extended_graduation'] = np.nan\n",
    "            return\n",
    "        \n",
    "        graduated_mask = self.master_df['is_graduated'] == True\n",
    "        \n",
    "        self.master_df['extended_graduation'] = np.where(\n",
    "            graduated_mask,\n",
    "            (self.master_df['total_semesters'] > 8).astype(int),\n",
    "            np.nan\n",
    "        )\n",
    "        \n",
    "        # Also create graduation speed categories\n",
    "        def categorize_graduation(row):\n",
    "            if not row.get('is_graduated', False):\n",
    "                return np.nan\n",
    "            semesters = row.get('total_semesters', np.nan)\n",
    "            if pd.isna(semesters):\n",
    "                return np.nan\n",
    "            elif semesters <= 8:\n",
    "                return 'On Time'\n",
    "            elif semesters <= 10:\n",
    "                return 'Slightly Extended'\n",
    "            else:\n",
    "                return 'Significantly Extended'\n",
    "        \n",
    "        self.master_df['graduation_speed'] = self.master_df.apply(categorize_graduation, axis=1)\n",
    "    \n",
    "    def _create_completion_target(self):\n",
    "        \"\"\"\n",
    "        NEW: Did the student complete their degree?\n",
    "        \n",
    "        Valid for: All NON-ACTIVE students (have final outcome)\n",
    "        Definition: \n",
    "            - 1 = Graduated successfully\n",
    "            - 0 = Withdrawn or Dismissed (did not complete)\n",
    "        \"\"\"\n",
    "        \n",
    "        active_mask = self.master_df['is_active'] == True\n",
    "        graduated_mask = self.master_df['is_graduated'] == True\n",
    "        \n",
    "        self.master_df['completed_degree'] = np.where(\n",
    "            ~active_mask,  # Has final outcome\n",
    "            graduated_mask.astype(int),\n",
    "            np.nan\n",
    "        )\n",
    "    \n",
    "    def _create_retention_target(self):\n",
    "        \"\"\"\n",
    "        NEW: Was the student retained after Year 1?\n",
    "        \n",
    "        Valid for: All students who completed Year 1\n",
    "        Definition: Student continued past Year 1 (not withdrawn/dismissed in Year 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(self.semester_records) == 0:\n",
    "            self.master_df['retained_after_y1'] = np.nan\n",
    "            return\n",
    "        \n",
    "        # Check if student has Year 2 data\n",
    "        if 'year_num' in self.semester_records.columns:\n",
    "            students_with_y2 = self.semester_records[\n",
    "                self.semester_records['year_num'] >= 2\n",
    "            ]['student_id'].unique()\n",
    "            \n",
    "            self.master_df['has_year2_data'] = self.master_df['student_id'].isin(students_with_y2)\n",
    "            \n",
    "            # Retained = has Year 2 data OR is currently active in Year 1 OR graduated\n",
    "            self.master_df['retained_after_y1'] = np.where(\n",
    "                self.master_df['completed_year1'],\n",
    "                (\n",
    "                    self.master_df['has_year2_data'] |\n",
    "                    self.master_df['is_graduated'] |\n",
    "                    self.master_df['is_active']\n",
    "                ).astype(int),\n",
    "                np.nan\n",
    "            )\n",
    "        else:\n",
    "            self.master_df['retained_after_y1'] = np.nan\n",
    "    \n",
    "    def _create_math_track(self):\n",
    "        \"\"\"Q7-Q8: Math track indicators\"\"\"\n",
    "        \n",
    "        # Look for existing math track column\n",
    "        math_track_cols = [col for col in self.master_df.columns \n",
    "                          if 'math' in col.lower() and 'placement' in col.lower()]\n",
    "        \n",
    "        if math_track_cols:\n",
    "            self.master_df['math_track'] = self.master_df[math_track_cols[0]]\n",
    "        elif 'math_score' in self.master_df.columns:\n",
    "            self.master_df['math_track'] = self.master_df['math_score'].apply(\n",
    "                self._infer_math_track\n",
    "            )\n",
    "        else:\n",
    "            self.master_df['math_track'] = 'Unknown'\n",
    "        \n",
    "        # CS major indicator\n",
    "        program_col = None\n",
    "        for col in ['Offer course name', 'final_program', 'Program']:\n",
    "            if col in self.master_df.columns:\n",
    "                program_col = col\n",
    "                break\n",
    "        \n",
    "        if program_col:\n",
    "            self.master_df['is_cs_major'] = self.master_df[program_col].astype(str).str.contains(\n",
    "                'Computer Science|Computer Engineering|CS',\n",
    "                case=False,\n",
    "                na=False\n",
    "            ).astype(int)\n",
    "        else:\n",
    "            self.master_df['is_cs_major'] = 0\n",
    "    \n",
    "    def _infer_math_track(self, score):\n",
    "        \"\"\"Infer math track from score\"\"\"\n",
    "        if pd.isna(score):\n",
    "            return 'Unknown'\n",
    "        \n",
    "        try:\n",
    "            score = float(score)\n",
    "        except (ValueError, TypeError):\n",
    "            # Handle letter grades (WASSCE)\n",
    "            wassce_map = {\n",
    "                'A1': 1, 'B2': 2, 'B3': 3, 'C4': 4, \n",
    "                'C5': 5, 'C6': 6, 'D7': 7, 'E8': 8, 'F9': 9\n",
    "            }\n",
    "            score = wassce_map.get(str(score).upper(), 5)\n",
    "        \n",
    "        # For WASSCE-style (1-9, lower is better)\n",
    "        if score <= 9:\n",
    "            if score <= 2:\n",
    "                return 'Calculus'\n",
    "            elif score <= 4:\n",
    "                return 'Pre-Calculus'\n",
    "            else:\n",
    "                return 'College Algebra'\n",
    "        # For percentage-style (0-100, higher is better)\n",
    "        else:\n",
    "            if score >= 80:\n",
    "                return 'Calculus'\n",
    "            elif score >= 60:\n",
    "                return 'Pre-Calculus'\n",
    "            else:\n",
    "                return 'College Algebra'\n",
    "    \n",
    "    def _print_target_summary(self):\n",
    "        \"\"\"Print summary of target variable validity\"\"\"\n",
    "        \n",
    "        print(\"\\n    Target Variable Summary:\")\n",
    "        print(\"    \" + \"-\" * 50)\n",
    "        \n",
    "        targets = [\n",
    "            ('first_year_struggle', 'All who completed Y1'),\n",
    "            ('has_ajc_case', 'All students'),\n",
    "            ('major_success', 'Graduated only'),\n",
    "            ('major_struggle', 'Graduated + Dismissed'),\n",
    "            ('extended_graduation', 'Graduated only'),\n",
    "            ('completed_degree', 'Non-active students'),\n",
    "            ('retained_after_y1', 'All who completed Y1')\n",
    "        ]\n",
    "        \n",
    "        for target, valid_for in targets:\n",
    "            if target in self.master_df.columns:\n",
    "                valid = self.master_df[target].notna().sum()\n",
    "                total = len(self.master_df)\n",
    "                \n",
    "                if valid > 0:\n",
    "                    positive = (self.master_df[target] == 1).sum()\n",
    "                    pos_rate = positive / valid * 100\n",
    "                    print(f\"    {target}:\")\n",
    "                    print(f\"      Valid: {valid}/{total} ({valid/total*100:.1f}%)\")\n",
    "                    print(f\"      Positive rate: {pos_rate:.1f}%\")\n",
    "                    print(f\"      Use for: {valid_for}\")\n",
    "                else:\n",
    "                    print(f\"    {target}: No valid cases\")\n",
    "        \n",
    "        print(\"    \" + \"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc7e9ad1-9174-4093-870f-855fcd0e8720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PHASE 5] TARGET VARIABLE CREATION\n",
      "--------------------------------------------------\n",
      "  Identifying student status...\n",
      "    Student Status Distribution:\n",
      "      ├─ Graduated:  1,140\n",
      "      ├─ Active:     1,059\n",
      "      ├─ Withdrawn:  0\n",
      "      ├─ Dismissed:  0\n",
      "      └─ Other:      10,448\n",
      "  Creating target variables...\n",
      "\n",
      "    Target Variable Summary:\n",
      "    --------------------------------------------------\n",
      "    first_year_struggle:\n",
      "      Valid: 2344/12647 (18.5%)\n",
      "      Positive rate: 9.3%\n",
      "      Use for: All who completed Y1\n",
      "    has_ajc_case:\n",
      "      Valid: 12647/12647 (100.0%)\n",
      "      Positive rate: 0.8%\n",
      "      Use for: All students\n",
      "    major_success:\n",
      "      Valid: 1140/12647 (9.0%)\n",
      "      Positive rate: 63.9%\n",
      "      Use for: Graduated only\n",
      "    major_struggle:\n",
      "      Valid: 1140/12647 (9.0%)\n",
      "      Positive rate: 0.0%\n",
      "      Use for: Graduated + Dismissed\n",
      "    extended_graduation:\n",
      "      Valid: 1140/12647 (9.0%)\n",
      "      Positive rate: 32.7%\n",
      "      Use for: Graduated only\n",
      "    completed_degree:\n",
      "      Valid: 11588/12647 (91.6%)\n",
      "      Positive rate: 9.8%\n",
      "      Use for: Non-active students\n",
      "    retained_after_y1:\n",
      "      Valid: 2344/12647 (18.5%)\n",
      "      Positive rate: 98.1%\n",
      "      Use for: All who completed Y1\n",
      "    --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[PHASE 5] TARGET VARIABLE CREATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "target_creator = TargetCreator(master_df, semester_records)\n",
    "master_df = target_creator.create_all_targets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39191d19-aa9c-4f9a-8514-0b38b3683be7",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6022c222-83be-4d24-adc1-a98c45a7b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer:\n",
    "    \"\"\"Engineer features for modeling\"\"\"\n",
    "    \n",
    "    def __init__(self, master_df, semester_records):\n",
    "        self.master_df = master_df.copy() if master_df is not None else pd.DataFrame()\n",
    "        self.semester_records = semester_records.copy() if semester_records is not None else pd.DataFrame()\n",
    "    \n",
    "    def engineer_all_features(self):\n",
    "        \"\"\"Create all engineered features\"\"\"\n",
    "        \n",
    "        if len(self.master_df) == 0:\n",
    "            return self.master_df\n",
    "        \n",
    "        print(\"  Engineering features...\")\n",
    "        \n",
    "        self._academic_features()\n",
    "        self._demographic_features()\n",
    "        self._application_features()\n",
    "        self._family_features()\n",
    "        \n",
    "        print(f\"    ✓ Feature engineering complete\")\n",
    "        \n",
    "        return self.master_df\n",
    "    \n",
    "    def _academic_features(self):\n",
    "        \"\"\"Create academic performance features\"\"\"\n",
    "        \n",
    "        # Subject score aggregates\n",
    "        score_cols = ['math_score', 'english_score', 'science_score']\n",
    "        existing_scores = [c for c in score_cols if c in self.master_df.columns]\n",
    "        \n",
    "        if existing_scores:\n",
    "            # Convert any remaining letter grades to numeric\n",
    "            for col in existing_scores:\n",
    "                self.master_df[col] = pd.to_numeric(self.master_df[col], errors='coerce')\n",
    "            \n",
    "            self.master_df['avg_core_subjects'] = self.master_df[existing_scores].mean(axis=1)\n",
    "            self.master_df['score_variance'] = self.master_df[existing_scores].var(axis=1)\n",
    "    \n",
    "    def _demographic_features(self):\n",
    "        \"\"\"Create demographic features\"\"\"\n",
    "        \n",
    "        # Gender\n",
    "        if 'Gender' in self.master_df.columns:\n",
    "            self.master_df['is_female'] = (self.master_df['Gender'] == 'Female').astype(int)\n",
    "        \n",
    "        # Disadvantaged background\n",
    "        if 'Disadvantaged background' in self.master_df.columns:\n",
    "            self.master_df['is_disadvantaged'] = self.master_df['Disadvantaged background'].isin(\n",
    "                ['Yes', 'TRUE', True, 1, 'yes', 'Y']\n",
    "            ).astype(int)\n",
    "        \n",
    "        # Financial aid\n",
    "        aid_col = 'Extra question: Do you Need Financial Aid?'\n",
    "        if aid_col in self.master_df.columns:\n",
    "            self.master_df['needs_financial_aid'] = self.master_df[aid_col].isin(\n",
    "                ['Yes', 'TRUE', True, 1, 'yes', 'Y']\n",
    "            ).astype(int)\n",
    "        \n",
    "        # International (non-Country0 assuming Country0 is Ghana)\n",
    "        if 'Nationality' in self.master_df.columns:\n",
    "            self.master_df['is_international'] = (\n",
    "                self.master_df['Nationality'] != 'Country0'\n",
    "            ).astype(int)\n",
    "    \n",
    "    def _application_features(self):\n",
    "        \"\"\"Create application-based features\"\"\"\n",
    "        \n",
    "        # Previous application\n",
    "        prev_app_col = 'Extra question: Have you applied to Ashesi before? If \"yes\" indicate the year.'\n",
    "        if prev_app_col in self.master_df.columns:\n",
    "            self.master_df['has_previous_application'] = (\n",
    "                ~self.master_df[prev_app_col].isin(['No', 'no', 'N/A', np.nan, ''])\n",
    "            ).astype(int)\n",
    "        \n",
    "        # Ashesi event attendance\n",
    "        event_col = 'Extra question: Have you ever attended any Ashesi sponsored high school event? If \"yes\" please state event and year of attendance.'\n",
    "        if event_col in self.master_df.columns:\n",
    "            self.master_df['attended_ashesi_event'] = (\n",
    "                ~self.master_df[event_col].isin(['No', 'no', 'N/A', np.nan, ''])\n",
    "            ).astype(int)\n",
    "    \n",
    "    def _family_features(self):\n",
    "        \"\"\"Create family-related features\"\"\"\n",
    "        \n",
    "        # Family connection to Ashesi\n",
    "        family_col = 'Extra question: Have any of your family members gained admission to Ashesi University?'\n",
    "        if family_col in self.master_df.columns:\n",
    "            self.master_df['has_family_connection'] = self.master_df[family_col].isin(\n",
    "                ['Yes', 'yes', 'Y', True, 1]\n",
    "            ).astype(int)\n",
    "        \n",
    "        # Family education level (from multiple columns)\n",
    "        edu_cols = [c for c in self.master_df.columns if 'Level of education' in c]\n",
    "        \n",
    "        edu_map = {\n",
    "            'PhD': 5, 'Doctorate': 5, 'phd': 5,\n",
    "            'Masters': 4, \"Master's\": 4, 'masters': 4, 'MSc': 4, 'MA': 4, 'MBA': 4,\n",
    "            'Bachelors': 3, \"Bachelor's\": 3, 'bachelors': 3, 'BSc': 3, 'BA': 3,\n",
    "            'Diploma': 2, 'HND': 2, 'diploma': 2,\n",
    "            'Secondary': 1, 'High School': 1, 'SE': 1, 'secondary': 1,\n",
    "            'Primary': 0, 'primary': 0, 'None': 0\n",
    "        }\n",
    "        \n",
    "        if edu_cols:\n",
    "            def get_max_education(row):\n",
    "                max_level = 0\n",
    "                for col in edu_cols:\n",
    "                    val = str(row.get(col, '')).strip()\n",
    "                    for key, level in edu_map.items():\n",
    "                        if key.lower() in val.lower():\n",
    "                            max_level = max(max_level, level)\n",
    "                            break\n",
    "                return max_level\n",
    "            \n",
    "            self.master_df['max_parent_education'] = self.master_df.apply(get_max_education, axis=1)\n",
    "    \n",
    "    def create_year_features(self, year):\n",
    "        \"\"\"Create features from specific year's data\"\"\"\n",
    "        \n",
    "        if len(self.semester_records) == 0 or 'year_num' not in self.semester_records.columns:\n",
    "            return self.master_df\n",
    "        \n",
    "        yr_data = self.semester_records[self.semester_records['year_num'] <= year]\n",
    "        \n",
    "        if len(yr_data) == 0:\n",
    "            return self.master_df\n",
    "        \n",
    "        agg_funcs = {}\n",
    "        if 'GPA' in yr_data.columns:\n",
    "            agg_funcs['GPA'] = ['mean', 'std', 'min', 'max']\n",
    "        if 'CGPA' in yr_data.columns:\n",
    "            agg_funcs['CGPA'] = 'last'\n",
    "        if 'on_probation' in yr_data.columns:\n",
    "            agg_funcs['on_probation'] = 'sum'\n",
    "        if 'deans_list' in yr_data.columns:\n",
    "            agg_funcs['deans_list'] = 'sum'\n",
    "        \n",
    "        if not agg_funcs:\n",
    "            return self.master_df\n",
    "        \n",
    "        yr_agg = yr_data.groupby('student_id').agg(agg_funcs)\n",
    "        \n",
    "        # Flatten columns\n",
    "        new_cols = []\n",
    "        for col in yr_agg.columns:\n",
    "            if isinstance(col, tuple):\n",
    "                new_cols.append(f'y{year}_{col[0]}_{col[1]}')\n",
    "            else:\n",
    "                new_cols.append(f'y{year}_{col}')\n",
    "        yr_agg.columns = new_cols\n",
    "        yr_agg = yr_agg.reset_index()\n",
    "        \n",
    "        self.master_df = self.master_df.merge(yr_agg, on='student_id', how='left')\n",
    "        \n",
    "        return self.master_df\n",
    "    \n",
    "    def get_feature_sets(self):\n",
    "        \"\"\"Define feature sets for different prediction tasks\"\"\"\n",
    "        \n",
    "        # Features available at admission time\n",
    "        admission_features = [\n",
    "            'standardized_score', 'math_score', 'english_score', 'science_score',\n",
    "            'avg_core_subjects', 'score_variance', 'performance_tier',\n",
    "            'is_female', 'is_disadvantaged', 'needs_financial_aid', 'is_international',\n",
    "            'has_previous_application', 'attended_ashesi_event', 'has_family_connection',\n",
    "            'max_parent_education', 'math_track', 'exam_source'\n",
    "        ]\n",
    "        \n",
    "        # Features after Year 1\n",
    "        year1_features = admission_features + [\n",
    "            'y1_GPA_mean', 'y1_GPA_std', 'y1_GPA_min', 'y1_GPA_max',\n",
    "            'y1_CGPA_last', 'y1_on_probation_sum', 'y1_deans_list_sum'\n",
    "        ]\n",
    "        \n",
    "        # Features after Year 2\n",
    "        year2_features = year1_features + [\n",
    "            'y2_GPA_mean', 'y2_GPA_std', 'y2_GPA_min', 'y2_GPA_max',\n",
    "            'y2_CGPA_last', 'y2_on_probation_sum', 'y2_deans_list_sum'\n",
    "        ]\n",
    "        \n",
    "        # Filter to existing columns\n",
    "        return {\n",
    "            'admission': [f for f in admission_features if f in self.master_df.columns],\n",
    "            'year1': [f for f in year1_features if f in self.master_df.columns],\n",
    "            'year2': [f for f in year2_features if f in self.master_df.columns]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4ca00c2-1a5e-4d41-8dd7-f4ff228a4ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PHASE 6] FEATURE ENGINEERING\n",
      "--------------------------------------------------\n",
      "  Engineering features...\n",
      "    ✓ Feature engineering complete\n",
      "\n",
      "  Saving processed data...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[PHASE 6] FEATURE ENGINEERING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "engineer = FeatureEngineer(master_df, semester_records)\n",
    "master_df = engineer.engineer_all_features()\n",
    "master_df = engineer.create_year_features(1)\n",
    "master_df = engineer.create_year_features(2)\n",
    "feature_sets = engineer.get_feature_sets()\n",
    "\n",
    "print(\"\\n  Saving processed data...\")\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "master_df.to_csv('data/processed/master_student_data.csv', index=False)\n",
    "if semester_records is not None:\n",
    "    semester_records.to_csv('data/processed/semester_records.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b1d6df-9429-4c60-8c39-66cfbe0cce79",
   "metadata": {},
   "source": [
    "#### UNSUPERVISED LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "582a5842-c3be-47fd-a3af-cbc94fe1e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43983cfe-ff90-4707-a2f5-88664a80265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupervisedAnalyzer:\n",
    "    \"\"\"\n",
    "    Unsupervised learning for student segmentation and pattern discovery\n",
    "    \n",
    "    Goals:\n",
    "    1. Identify natural student clusters/segments\n",
    "    2. Discover patterns in admission and performance data\n",
    "    3. Find at-risk student profiles\n",
    "    4. Support targeted intervention strategies\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, master_df, feature_sets, output_dir='reports/figures/'):\n",
    "        self.master_df = master_df.copy()\n",
    "        self.feature_sets = feature_sets\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        self.X_scaled = None\n",
    "        self.features_used = None\n",
    "        self.cluster_labels = {}\n",
    "        self.cluster_profiles = {}\n",
    "        self.results = {}\n",
    "        \n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    \n",
    "    def prepare_data(self, feature_type='admission'):\n",
    "        \"\"\"Prepare data for clustering\"\"\"\n",
    "        \n",
    "        print(\"  Preparing data for clustering...\")\n",
    "        \n",
    "        features = self.feature_sets.get(feature_type, [])\n",
    "        \n",
    "        # Exclude non-predictive columns\n",
    "        exclude_cols = [\n",
    "            'student_id', 'is_graduated', 'is_active', 'is_withdrawn', \n",
    "            'is_dismissed', 'has_final_outcome', 'completed_year1',\n",
    "            'student_status', 'Student Status'\n",
    "        ]\n",
    "        \n",
    "        features = [f for f in features if f in self.master_df.columns and f not in exclude_cols]\n",
    "        \n",
    "        if len(features) < 3:\n",
    "            print(f\"    ✗ Insufficient features ({len(features)})\")\n",
    "            return None\n",
    "        \n",
    "        # Get data\n",
    "        df = self.master_df[features].copy()\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        self.encoders = {}\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = df[col].fillna('Unknown')\n",
    "                le = LabelEncoder()\n",
    "                df[col] = le.fit_transform(df[col].astype(str))\n",
    "                self.encoders[col] = le\n",
    "            else:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        self.X_scaled = scaler.fit_transform(df)\n",
    "        self.features_used = features\n",
    "        self.scaler = scaler\n",
    "        \n",
    "        print(f\"    ✓ Prepared {len(self.X_scaled)} samples with {len(features)} features\")\n",
    "        \n",
    "        return self.X_scaled\n",
    "    \n",
    "    def find_optimal_clusters(self, max_k=10, method='kmeans'):\n",
    "        \"\"\"\n",
    "        Find optimal number of clusters using multiple metrics\n",
    "        \n",
    "        Methods:\n",
    "        - Elbow method (inertia)\n",
    "        - Silhouette score\n",
    "        - Calinski-Harabasz index\n",
    "        - Davies-Bouldin index\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.X_scaled is None:\n",
    "            print(\"    ✗ Data not prepared. Call prepare_data() first.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n  Finding optimal clusters (max_k={max_k})...\")\n",
    "        \n",
    "        results = {\n",
    "            'k': list(range(2, max_k + 1)),\n",
    "            'inertia': [],\n",
    "            'silhouette': [],\n",
    "            'calinski_harabasz': [],\n",
    "            'davies_bouldin': []\n",
    "        }\n",
    "        \n",
    "        for k in range(2, max_k + 1):\n",
    "            if method == 'kmeans':\n",
    "                model = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            elif method == 'gmm':\n",
    "                model = GaussianMixture(n_components=k, random_state=42)\n",
    "            \n",
    "            labels = model.fit_predict(self.X_scaled)\n",
    "            \n",
    "            # Metrics\n",
    "            if hasattr(model, 'inertia_'):\n",
    "                results['inertia'].append(model.inertia_)\n",
    "            else:\n",
    "                results['inertia'].append(None)\n",
    "            \n",
    "            results['silhouette'].append(silhouette_score(self.X_scaled, labels))\n",
    "            results['calinski_harabasz'].append(calinski_harabasz_score(self.X_scaled, labels))\n",
    "            results['davies_bouldin'].append(davies_bouldin_score(self.X_scaled, labels))\n",
    "        \n",
    "        # Find optimal k\n",
    "        # Silhouette: higher is better\n",
    "        optimal_silhouette = results['k'][np.argmax(results['silhouette'])]\n",
    "        # Davies-Bouldin: lower is better\n",
    "        optimal_db = results['k'][np.argmin(results['davies_bouldin'])]\n",
    "        \n",
    "        print(f\"    Optimal k by silhouette: {optimal_silhouette}\")\n",
    "        print(f\"    Optimal k by Davies-Bouldin: {optimal_db}\")\n",
    "        \n",
    "        # Plot\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # Elbow plot\n",
    "        if results['inertia'][0] is not None:\n",
    "            axes[0, 0].plot(results['k'], results['inertia'], 'bo-', linewidth=2, markersize=8)\n",
    "            axes[0, 0].set_xlabel('Number of Clusters (k)')\n",
    "            axes[0, 0].set_ylabel('Inertia')\n",
    "            axes[0, 0].set_title('Elbow Method')\n",
    "            axes[0, 0].grid(True)\n",
    "        \n",
    "        # Silhouette\n",
    "        axes[0, 1].plot(results['k'], results['silhouette'], 'go-', linewidth=2, markersize=8)\n",
    "        axes[0, 1].axvline(x=optimal_silhouette, color='r', linestyle='--', label=f'Optimal: {optimal_silhouette}')\n",
    "        axes[0, 1].set_xlabel('Number of Clusters (k)')\n",
    "        axes[0, 1].set_ylabel('Silhouette Score')\n",
    "        axes[0, 1].set_title('Silhouette Score (higher is better)')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # Calinski-Harabasz\n",
    "        axes[1, 0].plot(results['k'], results['calinski_harabasz'], 'mo-', linewidth=2, markersize=8)\n",
    "        axes[1, 0].set_xlabel('Number of Clusters (k)')\n",
    "        axes[1, 0].set_ylabel('Calinski-Harabasz Index')\n",
    "        axes[1, 0].set_title('Calinski-Harabasz Index (higher is better)')\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        # Davies-Bouldin\n",
    "        axes[1, 1].plot(results['k'], results['davies_bouldin'], 'ro-', linewidth=2, markersize=8)\n",
    "        axes[1, 1].axvline(x=optimal_db, color='g', linestyle='--', label=f'Optimal: {optimal_db}')\n",
    "        axes[1, 1].set_xlabel('Number of Clusters (k)')\n",
    "        axes[1, 1].set_ylabel('Davies-Bouldin Index')\n",
    "        axes[1, 1].set_title('Davies-Bouldin Index (lower is better)')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}cluster_optimization.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.results['cluster_optimization'] = results\n",
    "        \n",
    "        # Recommend k (average of methods, rounded)\n",
    "        recommended_k = int(round((optimal_silhouette + optimal_db) / 2))\n",
    "        print(f\"    Recommended k: {recommended_k}\")\n",
    "        \n",
    "        return recommended_k, results\n",
    "    \n",
    "    def perform_clustering(self, n_clusters, method='kmeans'):\n",
    "        \"\"\"\n",
    "        Perform clustering with specified method\n",
    "        \n",
    "        Methods:\n",
    "        - kmeans: K-Means clustering\n",
    "        - gmm: Gaussian Mixture Model\n",
    "        - hierarchical: Agglomerative clustering\n",
    "        - dbscan: DBSCAN (density-based)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.X_scaled is None:\n",
    "            print(\"    ✗ Data not prepared\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n  Performing {method} clustering with k={n_clusters}...\")\n",
    "        \n",
    "        if method == 'kmeans':\n",
    "            model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "            labels = model.fit_predict(self.X_scaled)\n",
    "            \n",
    "        elif method == 'gmm':\n",
    "            model = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "            labels = model.fit_predict(self.X_scaled)\n",
    "            \n",
    "        elif method == 'hierarchical':\n",
    "            model = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "            labels = model.fit_predict(self.X_scaled)\n",
    "            \n",
    "        elif method == 'dbscan':\n",
    "            model = DBSCAN(eps=0.5, min_samples=5)\n",
    "            labels = model.fit_predict(self.X_scaled)\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            print(f\"    DBSCAN found {n_clusters} clusters\")\n",
    "        \n",
    "        self.cluster_labels[method] = labels\n",
    "        self.master_df[f'cluster_{method}'] = labels\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if len(set(labels)) > 1:\n",
    "            metrics = {\n",
    "                'n_clusters': n_clusters,\n",
    "                'silhouette': silhouette_score(self.X_scaled, labels),\n",
    "                'calinski_harabasz': calinski_harabasz_score(self.X_scaled, labels),\n",
    "                'davies_bouldin': davies_bouldin_score(self.X_scaled, labels)\n",
    "            }\n",
    "            print(f\"    Silhouette: {metrics['silhouette']:.3f}\")\n",
    "        else:\n",
    "            metrics = {'n_clusters': n_clusters}\n",
    "        \n",
    "        self.results[f'{method}_metrics'] = metrics\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def analyze_clusters(self, cluster_col='cluster_kmeans'):\n",
    "        \"\"\"\n",
    "        Analyze characteristics of each cluster\n",
    "        \"\"\"\n",
    "        \n",
    "        if cluster_col not in self.master_df.columns:\n",
    "            print(f\"    ✗ Cluster column '{cluster_col}' not found\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n  Analyzing clusters from '{cluster_col}'...\")\n",
    "        \n",
    "        # Define metrics to analyze\n",
    "        outcome_cols = [\n",
    "            'first_year_struggle', 'has_ajc_case', 'major_success',\n",
    "            'major_struggle', 'extended_graduation', 'completed_degree'\n",
    "        ]\n",
    "        \n",
    "        performance_cols = [\n",
    "            'final_cgpa', 'y1_cgpa', 'standardized_score', 'avg_core_subjects'\n",
    "        ]\n",
    "        \n",
    "        demographic_cols = [\n",
    "            'is_female', 'is_international', 'needs_financial_aid', 'is_disadvantaged'\n",
    "        ]\n",
    "        \n",
    "        # Build aggregation\n",
    "        agg_dict = {'student_id': 'count'}\n",
    "        \n",
    "        for col in outcome_cols + performance_cols + demographic_cols:\n",
    "            if col in self.master_df.columns:\n",
    "                agg_dict[col] = 'mean'\n",
    "        \n",
    "        cluster_summary = self.master_df.groupby(cluster_col).agg(agg_dict).round(3)\n",
    "        cluster_summary = cluster_summary.rename(columns={'student_id': 'count'})\n",
    "        \n",
    "        # Calculate percentages\n",
    "        total = cluster_summary['count'].sum()\n",
    "        cluster_summary['pct_of_total'] = (cluster_summary['count'] / total * 100).round(1)\n",
    "        \n",
    "        # Create cluster profiles/names\n",
    "        def create_profile_name(row):\n",
    "            profiles = []\n",
    "            \n",
    "            # Academic performance\n",
    "            if 'final_cgpa' in row and pd.notna(row.get('final_cgpa')):\n",
    "                if row['final_cgpa'] >= 3.5:\n",
    "                    profiles.append('High Achievers')\n",
    "                elif row['final_cgpa'] >= 3.0:\n",
    "                    profiles.append('Solid Performers')\n",
    "                elif row['final_cgpa'] < 2.5:\n",
    "                    profiles.append('Struggling')\n",
    "            \n",
    "            # Risk indicators\n",
    "            if 'first_year_struggle' in row and row.get('first_year_struggle', 0) > 0.4:\n",
    "                profiles.append('At-Risk')\n",
    "            \n",
    "            if 'has_ajc_case' in row and row.get('has_ajc_case', 0) > 0.2:\n",
    "                profiles.append('Conduct Issues')\n",
    "            \n",
    "            # Demographics\n",
    "            if 'is_international' in row and row.get('is_international', 0) > 0.5:\n",
    "                profiles.append('International')\n",
    "            \n",
    "            if 'needs_financial_aid' in row and row.get('needs_financial_aid', 0) > 0.7:\n",
    "                profiles.append('Financial Need')\n",
    "            \n",
    "            if not profiles:\n",
    "                profiles.append('Average')\n",
    "            \n",
    "            return ' / '.join(profiles[:2])  # Max 2 descriptors\n",
    "        \n",
    "        cluster_summary['profile'] = cluster_summary.apply(create_profile_name, axis=1)\n",
    "        \n",
    "        self.cluster_profiles[cluster_col] = cluster_summary\n",
    "        \n",
    "        print(\"\\n    Cluster Profiles:\")\n",
    "        print(\"    \" + \"-\" * 60)\n",
    "        \n",
    "        for idx, row in cluster_summary.iterrows():\n",
    "            print(f\"    Cluster {idx}: {row['profile']}\")\n",
    "            print(f\"      Size: {int(row['count'])} ({row['pct_of_total']}%)\")\n",
    "            if 'final_cgpa' in row:\n",
    "                print(f\"      Avg CGPA: {row.get('final_cgpa', 'N/A'):.2f}\" if pd.notna(row.get('final_cgpa')) else \"      Avg CGPA: N/A\")\n",
    "            if 'first_year_struggle' in row:\n",
    "                print(f\"      Struggle Rate: {row.get('first_year_struggle', 0)*100:.1f}%\")\n",
    "            print()\n",
    "        \n",
    "        return cluster_summary\n",
    "    \n",
    "    def visualize_clusters(self, cluster_col='cluster_kmeans', method='pca'):\n",
    "        \"\"\"\n",
    "        Visualize clusters using dimensionality reduction\n",
    "        \n",
    "        Methods:\n",
    "        - pca: Principal Component Analysis\n",
    "        - tsne: t-SNE\n",
    "        - both: Both PCA and t-SNE\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.X_scaled is None or cluster_col not in self.master_df.columns:\n",
    "            print(\"    ✗ Data or clusters not available\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n  Visualizing clusters using {method}...\")\n",
    "        \n",
    "        labels = self.master_df[cluster_col].values\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2 if method == 'both' else 1, \n",
    "                                  figsize=(14 if method == 'both' else 8, 6))\n",
    "        \n",
    "        if method != 'both':\n",
    "            axes = [axes]\n",
    "        \n",
    "        # Color palette\n",
    "        n_clusters = len(set(labels))\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, n_clusters))\n",
    "        \n",
    "        # PCA\n",
    "        if method in ['pca', 'both']:\n",
    "            ax = axes[0]\n",
    "            \n",
    "            pca = PCA(n_components=2)\n",
    "            X_pca = pca.fit_transform(self.X_scaled)\n",
    "            \n",
    "            scatter = ax.scatter(\n",
    "                X_pca[:, 0], X_pca[:, 1],\n",
    "                c=labels, cmap='viridis', alpha=0.6, s=50\n",
    "            )\n",
    "            \n",
    "            ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "            ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "            ax.set_title(f'PCA Visualization\\n(Total variance: {sum(pca.explained_variance_ratio_)*100:.1f}%)')\n",
    "            \n",
    "            # Add cluster centers\n",
    "            for cluster_id in set(labels):\n",
    "                mask = labels == cluster_id\n",
    "                center = X_pca[mask].mean(axis=0)\n",
    "                ax.annotate(\n",
    "                    f'C{cluster_id}',\n",
    "                    center,\n",
    "                    fontsize=12,\n",
    "                    fontweight='bold',\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "                )\n",
    "            \n",
    "            plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "        \n",
    "        # t-SNE\n",
    "        if method in ['tsne', 'both']:\n",
    "            ax = axes[-1]\n",
    "            \n",
    "            # t-SNE is slow, use subset if data is large\n",
    "            if len(self.X_scaled) > 5000:\n",
    "                print(\"    Using subset for t-SNE (5000 samples)...\")\n",
    "                idx = np.random.choice(len(self.X_scaled), 5000, replace=False)\n",
    "                X_subset = self.X_scaled[idx]\n",
    "                labels_subset = labels[idx]\n",
    "            else:\n",
    "                X_subset = self.X_scaled\n",
    "                labels_subset = labels\n",
    "            \n",
    "            tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "            X_tsne = tsne.fit_transform(X_subset)\n",
    "            \n",
    "            scatter = ax.scatter(\n",
    "                X_tsne[:, 0], X_tsne[:, 1],\n",
    "                c=labels_subset, cmap='viridis', alpha=0.6, s=50\n",
    "            )\n",
    "            \n",
    "            ax.set_xlabel('t-SNE 1')\n",
    "            ax.set_ylabel('t-SNE 2')\n",
    "            ax.set_title('t-SNE Visualization')\n",
    "            \n",
    "            plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}cluster_visualization_{method}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"    ✓ Saved: {self.output_dir}cluster_visualization_{method}.png\")\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def cluster_feature_importance(self, cluster_col='cluster_kmeans'):\n",
    "        \"\"\"\n",
    "        Identify which features are most important for distinguishing clusters\n",
    "        \"\"\"\n",
    "        \n",
    "        if cluster_col not in self.master_df.columns:\n",
    "            return None\n",
    "        \n",
    "        print(\"\\n  Analyzing feature importance for clusters...\")\n",
    "        \n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        \n",
    "        # Use cluster labels as target\n",
    "        y = self.master_df[cluster_col].values\n",
    "        \n",
    "        # Train random forest to predict cluster membership\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        rf.fit(self.X_scaled, y)\n",
    "        \n",
    "        # Get feature importance\n",
    "        importance = pd.DataFrame({\n",
    "            'feature': self.features_used,\n",
    "            'importance': rf.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        top_n = min(15, len(importance))\n",
    "        top_features = importance.head(top_n)\n",
    "        \n",
    "        colors = plt.cm.viridis(np.linspace(0.2, 0.8, top_n))[::-1]\n",
    "        \n",
    "        ax.barh(top_features['feature'], top_features['importance'], color=colors)\n",
    "        ax.set_xlabel('Importance')\n",
    "        ax.set_title('Features Most Important for Cluster Separation')\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}cluster_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"    Top 5 distinguishing features:\")\n",
    "        for i, row in importance.head(5).iterrows():\n",
    "            print(f\"      {row['feature']}: {row['importance']:.4f}\")\n",
    "        \n",
    "        return importance\n",
    "    \n",
    "    def identify_risk_clusters(self, cluster_col='cluster_kmeans'):\n",
    "        \"\"\"\n",
    "        Identify which clusters represent at-risk students\n",
    "        \"\"\"\n",
    "        \n",
    "        if cluster_col not in self.master_df.columns:\n",
    "            return None\n",
    "        \n",
    "        print(\"\\n  Identifying risk clusters...\")\n",
    "        \n",
    "        risk_indicators = [\n",
    "            'first_year_struggle', 'has_ajc_case', 'major_struggle',\n",
    "            'extended_graduation'\n",
    "        ]\n",
    "        \n",
    "        available_indicators = [r for r in risk_indicators if r in self.master_df.columns]\n",
    "        \n",
    "        if not available_indicators:\n",
    "            print(\"    ✗ No risk indicators available\")\n",
    "            return None\n",
    "        \n",
    "        # Calculate composite risk score per cluster\n",
    "        risk_scores = self.master_df.groupby(cluster_col)[available_indicators].mean()\n",
    "        risk_scores['composite_risk'] = risk_scores.mean(axis=1)\n",
    "        risk_scores['cluster_size'] = self.master_df.groupby(cluster_col).size()\n",
    "        \n",
    "        # Classify clusters\n",
    "        def classify_risk(score):\n",
    "            if score > 0.5:\n",
    "                return 'HIGH RISK'\n",
    "            elif score > 0.3:\n",
    "                return 'MODERATE RISK'\n",
    "            elif score > 0.15:\n",
    "                return 'LOW RISK'\n",
    "            else:\n",
    "                return 'MINIMAL RISK'\n",
    "        \n",
    "        risk_scores['risk_level'] = risk_scores['composite_risk'].apply(classify_risk)\n",
    "        \n",
    "        # Sort by risk\n",
    "        risk_scores = risk_scores.sort_values('composite_risk', ascending=False)\n",
    "        \n",
    "        print(\"\\n    Risk Assessment by Cluster:\")\n",
    "        print(\"    \" + \"-\" * 60)\n",
    "        \n",
    "        for cluster_id, row in risk_scores.iterrows():\n",
    "            print(f\"    Cluster {cluster_id}: {row['risk_level']}\")\n",
    "            print(f\"      Composite Risk Score: {row['composite_risk']:.3f}\")\n",
    "            print(f\"      Size: {int(row['cluster_size'])} students\")\n",
    "            for indicator in available_indicators:\n",
    "                print(f\"      {indicator}: {row[indicator]*100:.1f}%\")\n",
    "            print()\n",
    "        \n",
    "        self.results['risk_clusters'] = risk_scores\n",
    "        \n",
    "        return risk_scores\n",
    "    \n",
    "    def cluster_outcome_analysis(self, cluster_col='cluster_kmeans'):\n",
    "        \"\"\"\n",
    "        Analyze academic outcomes by cluster\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\n  Analyzing outcomes by cluster...\")\n",
    "        \n",
    "        outcome_cols = ['final_cgpa', 'major_success', 'extended_graduation', 'completed_degree']\n",
    "        available_outcomes = [c for c in outcome_cols if c in self.master_df.columns]\n",
    "        \n",
    "        if not available_outcomes:\n",
    "            print(\"    ✗ No outcome columns available\")\n",
    "            return None\n",
    "        \n",
    "        # Create visualization\n",
    "        n_outcomes = len(available_outcomes)\n",
    "        fig, axes = plt.subplots(1, n_outcomes, figsize=(5 * n_outcomes, 5))\n",
    "        \n",
    "        if n_outcomes == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for ax, outcome in zip(axes, available_outcomes):\n",
    "            if outcome == 'final_cgpa':\n",
    "                # Box plot for continuous outcome\n",
    "                data_to_plot = []\n",
    "                labels_to_plot = []\n",
    "                \n",
    "                for cluster in sorted(self.master_df[cluster_col].unique()):\n",
    "                    cluster_data = self.master_df[\n",
    "                        self.master_df[cluster_col] == cluster\n",
    "                    ][outcome].dropna()\n",
    "                    if len(cluster_data) > 0:\n",
    "                        data_to_plot.append(cluster_data)\n",
    "                        labels_to_plot.append(f'C{cluster}')\n",
    "                \n",
    "                ax.boxplot(data_to_plot, labels=labels_to_plot)\n",
    "                ax.axhline(y=2.0, color='r', linestyle='--', alpha=0.5)\n",
    "                ax.axhline(y=3.0, color='g', linestyle='--', alpha=0.5)\n",
    "                ax.set_ylabel('CGPA')\n",
    "                \n",
    "            else:\n",
    "                # Bar plot for binary outcomes\n",
    "                outcome_by_cluster = self.master_df.groupby(cluster_col)[outcome].mean()\n",
    "                bars = ax.bar(\n",
    "                    [f'C{c}' for c in outcome_by_cluster.index],\n",
    "                    outcome_by_cluster.values,\n",
    "                    color=plt.cm.RdYlGn(outcome_by_cluster.values) if 'success' in outcome or 'completed' in outcome\n",
    "                          else plt.cm.RdYlGn_r(outcome_by_cluster.values)\n",
    "                )\n",
    "                ax.set_ylabel('Rate')\n",
    "                ax.set_ylim(0, 1)\n",
    "            \n",
    "            ax.set_xlabel('Cluster')\n",
    "            ax.set_title(outcome.replace('_', ' ').title())\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}cluster_outcomes.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"    ✓ Saved: {self.output_dir}cluster_outcomes.png\")\n",
    "    \n",
    "    def run_full_analysis(self, feature_type='admission', n_clusters=None):\n",
    "        \"\"\"\n",
    "        Run complete unsupervised analysis pipeline\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"UNSUPERVISED LEARNING ANALYSIS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Step 1: Prepare data\n",
    "        self.prepare_data(feature_type)\n",
    "        \n",
    "        if self.X_scaled is None:\n",
    "            return None\n",
    "        \n",
    "        # Step 2: Find optimal clusters if not specified\n",
    "        if n_clusters is None:\n",
    "            n_clusters, _ = self.find_optimal_clusters(max_k=8)\n",
    "        \n",
    "        # Step 3: Perform clustering\n",
    "        self.perform_clustering(n_clusters, method='kmeans')\n",
    "        \n",
    "        # Also try GMM for comparison\n",
    "        self.perform_clustering(n_clusters, method='gmm')\n",
    "        \n",
    "        # Step 4: Analyze clusters\n",
    "        cluster_summary = self.analyze_clusters('cluster_kmeans')\n",
    "        \n",
    "        # Step 5: Visualize\n",
    "        self.visualize_clusters('cluster_kmeans', method='both')\n",
    "        \n",
    "        # Step 6: Feature importance\n",
    "        self.cluster_feature_importance('cluster_kmeans')\n",
    "        \n",
    "        # Step 7: Risk identification\n",
    "        self.identify_risk_clusters('cluster_kmeans')\n",
    "        \n",
    "        # Step 8: Outcome analysis\n",
    "        self.cluster_outcome_analysis('cluster_kmeans')\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"UNSUPERVISED ANALYSIS COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        return {\n",
    "            'cluster_summary': cluster_summary,\n",
    "            'risk_clusters': self.results.get('risk_clusters'),\n",
    "            'master_df_with_clusters': self.master_df\n",
    "        }\n",
    "    \n",
    "    def generate_cluster_report(self, output_path='reports/cluster_report.txt'):\n",
    "        \"\"\"Generate text report of clustering results\"\"\"\n",
    "        \n",
    "        lines = [\n",
    "            \"=\" * 70,\n",
    "            \"STUDENT SEGMENTATION REPORT\",\n",
    "            \"Unsupervised Learning Analysis\",\n",
    "            f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "            \"=\" * 70,\n",
    "            \"\"\n",
    "        ]\n",
    "        \n",
    "        # Clustering metrics\n",
    "        if 'kmeans_metrics' in self.results:\n",
    "            metrics = self.results['kmeans_metrics']\n",
    "            lines.extend([\n",
    "                \"CLUSTERING METRICS\",\n",
    "                \"-\" * 40,\n",
    "                f\"Number of clusters: {metrics.get('n_clusters', 'N/A')}\",\n",
    "                f\"Silhouette score: {metrics.get('silhouette', 'N/A'):.3f}\",\n",
    "                f\"Calinski-Harabasz index: {metrics.get('calinski_harabasz', 'N/A'):.1f}\",\n",
    "                f\"Davies-Bouldin index: {metrics.get('davies_bouldin', 'N/A'):.3f}\",\n",
    "                \"\"\n",
    "            ])\n",
    "        \n",
    "        # Cluster profiles\n",
    "        if 'cluster_kmeans' in self.cluster_profiles:\n",
    "            profiles = self.cluster_profiles['cluster_kmeans']\n",
    "            lines.extend([\n",
    "                \"CLUSTER PROFILES\",\n",
    "                \"-\" * 40\n",
    "            ])\n",
    "            \n",
    "            for idx, row in profiles.iterrows():\n",
    "                lines.append(f\"\\nCluster {idx}: {row['profile']}\")\n",
    "                lines.append(f\"  Size: {int(row['count'])} ({row['pct_of_total']}%)\")\n",
    "                \n",
    "                for col in row.index:\n",
    "                    if col not in ['count', 'pct_of_total', 'profile']:\n",
    "                        val = row[col]\n",
    "                        if pd.notna(val):\n",
    "                            if isinstance(val, float):\n",
    "                                lines.append(f\"  {col}: {val:.3f}\")\n",
    "            \n",
    "            lines.append(\"\")\n",
    "        \n",
    "        # Risk clusters\n",
    "        if 'risk_clusters' in self.results:\n",
    "            risk = self.results['risk_clusters']\n",
    "            lines.extend([\n",
    "                \"RISK ASSESSMENT\",\n",
    "                \"-\" * 40\n",
    "            ])\n",
    "            \n",
    "            for cluster_id, row in risk.iterrows():\n",
    "                lines.append(f\"\\nCluster {cluster_id}: {row['risk_level']}\")\n",
    "                lines.append(f\"  Composite Risk: {row['composite_risk']:.3f}\")\n",
    "                lines.append(f\"  Size: {int(row['cluster_size'])}\")\n",
    "        \n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            \"=\" * 70,\n",
    "            \"RECOMMENDATIONS FOR INTERVENTION\",\n",
    "            \"=\" * 70,\n",
    "            \"\"\n",
    "        ])\n",
    "        \n",
    "        # Generate recommendations based on clusters\n",
    "        if 'risk_clusters' in self.results:\n",
    "            high_risk = self.results['risk_clusters'][\n",
    "                self.results['risk_clusters']['risk_level'] == 'HIGH RISK'\n",
    "            ]\n",
    "            \n",
    "            if len(high_risk) > 0:\n",
    "                total_at_risk = high_risk['cluster_size'].sum()\n",
    "                lines.append(f\"• HIGH PRIORITY: {int(total_at_risk)} students in high-risk clusters\")\n",
    "                lines.append(\"  Recommended: Immediate academic intervention and support\")\n",
    "            \n",
    "            moderate_risk = self.results['risk_clusters'][\n",
    "                self.results['risk_clusters']['risk_level'] == 'MODERATE RISK'\n",
    "            ]\n",
    "            \n",
    "            if len(moderate_risk) > 0:\n",
    "                total_moderate = moderate_risk['cluster_size'].sum()\n",
    "                lines.append(f\"• MODERATE PRIORITY: {int(total_moderate)} students need monitoring\")\n",
    "                lines.append(\"  Recommended: Regular check-ins and preventive support\")\n",
    "        \n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            \"=\" * 70\n",
    "        ])\n",
    "        \n",
    "        report = \"\\n\".join(lines)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(f\"    ✓ Saved: {output_path}\")\n",
    "        \n",
    "        return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f7411ea-6316-4935-adca-3ac94eddbd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PHASE 6B] UNSUPERVISED LEARNING\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "UNSUPERVISED LEARNING ANALYSIS\n",
      "============================================================\n",
      "  Preparing data for clustering...\n",
      "    ✓ Prepared 12647 samples with 17 features\n",
      "\n",
      "  Finding optimal clusters (max_k=8)...\n",
      "    Optimal k by silhouette: 2\n",
      "    Optimal k by Davies-Bouldin: 8\n",
      "    Recommended k: 5\n",
      "\n",
      "  Performing kmeans clustering with k=5...\n",
      "    Silhouette: 0.189\n",
      "\n",
      "  Performing gmm clustering with k=5...\n",
      "    Silhouette: 0.206\n",
      "\n",
      "  Analyzing clusters from 'cluster_kmeans'...\n",
      "\n",
      "    Cluster Profiles:\n",
      "    ------------------------------------------------------------\n",
      "    Cluster 0: Solid Performers / International\n",
      "      Size: 3844 (30.4%)\n",
      "      Avg CGPA: 3.06\n",
      "      Struggle Rate: 10.0%\n",
      "\n",
      "    Cluster 1: Solid Performers\n",
      "      Size: 1030 (8.1%)\n",
      "      Avg CGPA: 3.04\n",
      "      Struggle Rate: 7.1%\n",
      "\n",
      "    Cluster 2: Solid Performers\n",
      "      Size: 7456 (59.0%)\n",
      "      Avg CGPA: 3.05\n",
      "      Struggle Rate: 10.3%\n",
      "\n",
      "    Cluster 3: Struggling / At-Risk\n",
      "      Size: 33 (0.3%)\n",
      "      Avg CGPA: 2.36\n",
      "      Struggle Rate: 51.5%\n",
      "\n",
      "    Cluster 4: Average\n",
      "      Size: 284 (2.2%)\n",
      "      Avg CGPA: 2.87\n",
      "      Struggle Rate: 9.2%\n",
      "\n",
      "\n",
      "  Visualizing clusters using both...\n",
      "    Using subset for t-SNE (5000 samples)...\n",
      "    ✓ Saved: reports/figures/cluster_visualization_both.png\n",
      "\n",
      "  Analyzing feature importance for clusters...\n",
      "    Top 5 distinguishing features:\n",
      "      is_international: 0.6678\n",
      "      math_track: 0.0763\n",
      "      performance_tier: 0.0599\n",
      "      exam_source: 0.0560\n",
      "      standardized_score: 0.0549\n",
      "\n",
      "  Identifying risk clusters...\n",
      "\n",
      "    Risk Assessment by Cluster:\n",
      "    ------------------------------------------------------------\n",
      "    Cluster 3: LOW RISK\n",
      "      Composite Risk Score: 0.261\n",
      "      Size: 33 students\n",
      "      first_year_struggle: 51.5%\n",
      "      has_ajc_case: 3.0%\n",
      "      major_struggle: 0.0%\n",
      "      extended_graduation: 50.0%\n",
      "\n",
      "    Cluster 4: LOW RISK\n",
      "      Composite Risk Score: 0.196\n",
      "      Size: 284 students\n",
      "      first_year_struggle: 9.2%\n",
      "      has_ajc_case: 4.2%\n",
      "      major_struggle: 0.0%\n",
      "      extended_graduation: 64.9%\n",
      "\n",
      "    Cluster 1: MINIMAL RISK\n",
      "      Composite Risk Score: 0.118\n",
      "      Size: 1030 students\n",
      "      first_year_struggle: 7.1%\n",
      "      has_ajc_case: 2.7%\n",
      "      major_struggle: 0.0%\n",
      "      extended_graduation: 37.3%\n",
      "\n",
      "    Cluster 2: MINIMAL RISK\n",
      "      Composite Risk Score: 0.088\n",
      "      Size: 7456 students\n",
      "      first_year_struggle: 10.3%\n",
      "      has_ajc_case: 0.7%\n",
      "      major_struggle: 0.0%\n",
      "      extended_graduation: 24.2%\n",
      "\n",
      "    Cluster 0: MINIMAL RISK\n",
      "      Composite Risk Score: 0.073\n",
      "      Size: 3844 students\n",
      "      first_year_struggle: 10.0%\n",
      "      has_ajc_case: 0.1%\n",
      "      major_struggle: 0.0%\n",
      "      extended_graduation: 19.2%\n",
      "\n",
      "\n",
      "  Analyzing outcomes by cluster...\n",
      "    ✓ Saved: reports/figures/cluster_outcomes.png\n",
      "\n",
      "============================================================\n",
      "UNSUPERVISED ANALYSIS COMPLETE\n",
      "============================================================\n",
      "    ✓ Saved: reports/cluster_report.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[PHASE 6B] UNSUPERVISED LEARNING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "unsupervised = UnsupervisedAnalyzer(master_df, feature_sets)\n",
    "unsupervised_results = unsupervised.run_full_analysis(feature_type='admission')\n",
    "\n",
    "if unsupervised_results:\n",
    "    master_df = unsupervised_results['master_df_with_clusters']\n",
    "    unsupervised.generate_cluster_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3099902-71b4-4780-b330-aa0ba4985208",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25b27af1-3616-4364-89ce-ab9ced7205ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, classification_report, confusion_matrix,\n",
    "    precision_recall_curve, roc_curve\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ebc27d8-654d-4663-aeef-400134acd4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Train and evaluate models with multiple split strategies\"\"\"\n",
    "    \n",
    "    def __init__(self, master_df, feature_sets, semester_records=None):\n",
    "        self.master_df = master_df.copy()\n",
    "        self.feature_sets = feature_sets\n",
    "        self.semester_records = semester_records\n",
    "        self.results = {}\n",
    "        self.best_models = {}\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "        self.split_info = {}\n",
    "    \n",
    "    def prepare_data(self, feature_type, target, split_method='random', \n",
    "                     test_size=0.2, test_years=None):\n",
    "        \"\"\"\n",
    "        Prepare data with flexible split strategies\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        feature_type : str\n",
    "            'admission', 'year1', or 'year2'\n",
    "        target : str\n",
    "            Target variable name\n",
    "        split_method : str\n",
    "            'random' - Random stratified split (default)\n",
    "            'temporal' - Split by year group\n",
    "        test_size : float\n",
    "            Proportion for test set (for random split)\n",
    "        test_years : list\n",
    "            Specific years to use as test set (for temporal split)\n",
    "        \"\"\"\n",
    "        \n",
    "        features = self.feature_sets.get(feature_type, [])\n",
    "        \n",
    "        if not features or target not in self.master_df.columns:\n",
    "            print(f\"    ✗ Missing features or target: {target}\")\n",
    "            return None\n",
    "        \n",
    "        # Get data with NON-NULL target (filters out invalid cases automatically)\n",
    "        df = self.master_df[self.master_df[target].notna()].copy()\n",
    "        \n",
    "        print(f\"      Valid samples for '{target}': {len(df)}\")\n",
    "        \n",
    "        # Filter to available features (exclude status flags)\n",
    "        exclude_cols = [\n",
    "            'is_graduated', 'is_active', 'is_withdrawn', 'is_dismissed',\n",
    "            'has_final_outcome', 'completed_year1', 'student_status', \n",
    "            'Student Status', 'student_id'\n",
    "        ]\n",
    "        available_features = [f for f in features \n",
    "                             if f in df.columns and f not in exclude_cols]\n",
    "        \n",
    "        if len(available_features) < 3:\n",
    "            print(f\"    ✗ Insufficient features ({len(available_features)})\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"      Using {len(available_features)} features\")\n",
    "        \n",
    "        # Choose split method\n",
    "        if split_method == 'temporal':\n",
    "            return self._temporal_split(df, available_features, target, test_years)\n",
    "        else:\n",
    "            return self._random_split(df, available_features, target, test_size)\n",
    "    \n",
    "    def _random_split(self, df, features, target, test_size=0.2):\n",
    "        \"\"\"Standard random stratified split\"\"\"\n",
    "        \n",
    "        X = df[features].copy()\n",
    "        y = df[target].astype(int).copy()\n",
    "        \n",
    "        # Encode categorical features\n",
    "        X = self._encode_features(X, f\"random_{target}\")\n",
    "        \n",
    "        # Check minimum samples\n",
    "        if len(X) < 50:\n",
    "            print(f\"    ✗ Insufficient samples ({len(X)})\")\n",
    "            return None\n",
    "        \n",
    "        # Check class distribution\n",
    "        class_counts = y.value_counts()\n",
    "        print(f\"      Class distribution: {dict(class_counts)}\")\n",
    "        \n",
    "        if len(class_counts) < 2:\n",
    "            print(f\"    ✗ Only one class present\")\n",
    "            return None\n",
    "        \n",
    "        if class_counts.min() < 5:\n",
    "            print(f\"    ⚠️ Minority class very small ({class_counts.min()})\")\n",
    "        \n",
    "        # Split\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y,\n",
    "                test_size=test_size,\n",
    "                random_state=42,\n",
    "                stratify=y\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"    ✗ Split failed: {e}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"      Split: Train={len(X_train)}, Test={len(X_test)}\")\n",
    "        \n",
    "        # Scale\n",
    "        X_train_scaled, X_test_scaled, scaler = self._scale_features(\n",
    "            X_train, X_test, features, f\"random_{target}\"\n",
    "        )\n",
    "        \n",
    "        # Handle imbalance\n",
    "        X_train_scaled, y_train = self._handle_imbalance(X_train_scaled, y_train)\n",
    "        \n",
    "        self.split_info[target] = {\n",
    "            'method': 'random',\n",
    "            'test_size': test_size,\n",
    "            'train_size': len(X_train_scaled),\n",
    "            'test_size_actual': len(X_test)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'X_train': X_train_scaled,\n",
    "            'X_test': X_test_scaled,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test,\n",
    "            'features': features\n",
    "        }\n",
    "    \n",
    "    def _temporal_split(self, df, features, target, test_years=None):\n",
    "        \"\"\"\n",
    "        Temporal split - train on older cohorts, test on newer cohorts\n",
    "        \n",
    "        This is more realistic for predicting future student outcomes\n",
    "        \"\"\"\n",
    "        \n",
    "        # Find year column\n",
    "        yg_col = None\n",
    "        for col in ['Yeargroup', 'yeargroup', 'Year Group']:\n",
    "            if col in df.columns:\n",
    "                yg_col = col\n",
    "                break\n",
    "        \n",
    "        if yg_col is None:\n",
    "            print(\"    ⚠️ No year column found, falling back to random split\")\n",
    "            return self._random_split(df, features, target)\n",
    "        \n",
    "        # Get years sorted\n",
    "        df[yg_col] = pd.to_numeric(df[yg_col], errors='coerce')\n",
    "        df = df.dropna(subset=[yg_col])\n",
    "        \n",
    "        years = sorted(df[yg_col].unique())\n",
    "        print(f\"      Available years: {years}\")\n",
    "        \n",
    "        if len(years) < 2:\n",
    "            print(\"    ⚠️ Only one year available, falling back to random split\")\n",
    "            return self._random_split(df, features, target)\n",
    "        \n",
    "        # Determine test years\n",
    "        if test_years is None:\n",
    "            # Use most recent 20-25% of years as test\n",
    "            n_test_years = max(1, len(years) // 4)\n",
    "            test_years = years[-n_test_years:]\n",
    "        \n",
    "        train_years = [y for y in years if y not in test_years]\n",
    "        \n",
    "        print(f\"      Train years: {train_years}\")\n",
    "        print(f\"      Test years: {test_years}\")\n",
    "        \n",
    "        # Split data\n",
    "        train_mask = df[yg_col].isin(train_years)\n",
    "        test_mask = df[yg_col].isin(test_years)\n",
    "        \n",
    "        train_df = df[train_mask]\n",
    "        test_df = df[test_mask]\n",
    "        \n",
    "        if len(train_df) < 30 or len(test_df) < 10:\n",
    "            print(f\"    ⚠️ Insufficient data for temporal split, falling back to random\")\n",
    "            return self._random_split(df, features, target)\n",
    "        \n",
    "        X_train = train_df[features].copy()\n",
    "        y_train = train_df[target].astype(int).copy()\n",
    "        X_test = test_df[features].copy()\n",
    "        y_test = test_df[target].astype(int).copy()\n",
    "        \n",
    "        print(f\"      Split: Train={len(X_train)} ({train_years}), Test={len(X_test)} ({test_years})\")\n",
    "        \n",
    "        # Encode (fit on train, transform both)\n",
    "        X_train = self._encode_features(X_train, f\"temporal_{target}\", fit=True)\n",
    "        X_test = self._encode_features(X_test, f\"temporal_{target}\", fit=False)\n",
    "        \n",
    "        # Check class distribution in both sets\n",
    "        print(f\"      Train class dist: {dict(y_train.value_counts())}\")\n",
    "        print(f\"      Test class dist: {dict(y_test.value_counts())}\")\n",
    "        \n",
    "        # Scale\n",
    "        X_train_scaled, X_test_scaled, scaler = self._scale_features(\n",
    "            X_train, X_test, features, f\"temporal_{target}\"\n",
    "        )\n",
    "        \n",
    "        # Handle imbalance (only on training data)\n",
    "        X_train_scaled, y_train = self._handle_imbalance(X_train_scaled, y_train)\n",
    "        \n",
    "        self.split_info[target] = {\n",
    "            'method': 'temporal',\n",
    "            'train_years': train_years,\n",
    "            'test_years': test_years,\n",
    "            'train_size': len(X_train_scaled),\n",
    "            'test_size': len(X_test)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'X_train': X_train_scaled,\n",
    "            'X_test': X_test_scaled,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test,\n",
    "            'features': features,\n",
    "            'train_years': train_years,\n",
    "            'test_years': test_years\n",
    "        }\n",
    "    \n",
    "    def _encode_features(self, X, key_prefix, fit=True):\n",
    "        \"\"\"Encode categorical features\"\"\"\n",
    "        \n",
    "        X = X.copy()\n",
    "        \n",
    "        for col in X.columns:\n",
    "            if X[col].dtype == 'object':\n",
    "                X[col] = X[col].fillna('Unknown')\n",
    "                \n",
    "                encoder_key = f\"{key_prefix}_{col}\"\n",
    "                \n",
    "                if fit:\n",
    "                    le = LabelEncoder()\n",
    "                    X[col] = le.fit_transform(X[col].astype(str))\n",
    "                    self.encoders[encoder_key] = le\n",
    "                else:\n",
    "                    if encoder_key in self.encoders:\n",
    "                        le = self.encoders[encoder_key]\n",
    "                        # Handle unseen categories\n",
    "                        X[col] = X[col].apply(\n",
    "                            lambda x: x if x in le.classes_ else 'Unknown'\n",
    "                        )\n",
    "                        X[col] = le.transform(X[col].astype(str))\n",
    "                    else:\n",
    "                        le = LabelEncoder()\n",
    "                        X[col] = le.fit_transform(X[col].astype(str))\n",
    "            else:\n",
    "                X[col] = X[col].fillna(X[col].median())\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def _scale_features(self, X_train, X_test, features, key):\n",
    "        \"\"\"Scale features\"\"\"\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        X_train_scaled = pd.DataFrame(\n",
    "            scaler.fit_transform(X_train),\n",
    "            columns=features,\n",
    "            index=X_train.index\n",
    "        )\n",
    "        \n",
    "        X_test_scaled = pd.DataFrame(\n",
    "            scaler.transform(X_test),\n",
    "            columns=features,\n",
    "            index=X_test.index\n",
    "        )\n",
    "        \n",
    "        self.scalers[key] = scaler\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, scaler\n",
    "    \n",
    "    def _handle_imbalance(self, X_train, y_train):\n",
    "        \"\"\"Handle class imbalance with SMOTE\"\"\"\n",
    "        \n",
    "        class_counts = y_train.value_counts()\n",
    "        class_ratio = class_counts.min() / class_counts.max()\n",
    "        \n",
    "        if class_ratio < 0.3 and len(y_train) > 100:\n",
    "            print(f\"      Applying SMOTE (ratio: {class_ratio:.2f})\")\n",
    "            try:\n",
    "                from imblearn.over_sampling import SMOTE\n",
    "                smote = SMOTE(random_state=42, k_neighbors=min(5, class_counts.min() - 1))\n",
    "                X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "                print(f\"      After SMOTE: {len(X_resampled)} samples\")\n",
    "                return pd.DataFrame(X_resampled, columns=X_train.columns), pd.Series(y_resampled)\n",
    "            except ImportError:\n",
    "                print(\"      ⚠️ imbalanced-learn not installed\")\n",
    "            except Exception as e:\n",
    "                print(f\"      ⚠️ SMOTE failed: {e}\")\n",
    "        \n",
    "        return X_train, y_train\n",
    "    \n",
    "    def get_models(self):\n",
    "        \"\"\"Define models to evaluate\"\"\"\n",
    "        \n",
    "        return {\n",
    "            'Logistic Regression': LogisticRegression(\n",
    "                max_iter=1000, random_state=42, class_weight='balanced'\n",
    "            ),\n",
    "            'Random Forest': RandomForestClassifier(\n",
    "                n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1\n",
    "            ),\n",
    "            'Gradient Boosting': GradientBoostingClassifier(\n",
    "                n_estimators=100, random_state=42\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def train_task(self, feature_type, target, split_method='temporal'):\n",
    "        \"\"\"Train models for a specific prediction task\"\"\"\n",
    "        \n",
    "        task_key = f\"{feature_type}_{target}\"\n",
    "        print(f\"\\n    Training: {task_key} (split: {split_method})\")\n",
    "        \n",
    "        data = self.prepare_data(feature_type, target, split_method=split_method)\n",
    "        \n",
    "        if data is None:\n",
    "            return None\n",
    "        \n",
    "        X_train = data['X_train']\n",
    "        X_test = data['X_test']\n",
    "        y_train = data['y_train']\n",
    "        y_test = data['y_test']\n",
    "        features = data['features']\n",
    "        \n",
    "        models = self.get_models()\n",
    "        \n",
    "        best_auc = 0\n",
    "        best_model_name = None\n",
    "        task_results = {}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            try:\n",
    "                # Cross-validation on training data\n",
    "                cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "                cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "                \n",
    "                # Fit on full training set\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Predict on test set\n",
    "                y_pred = model.predict(X_test)\n",
    "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "                \n",
    "                # Calculate metrics\n",
    "                metrics = {\n",
    "                    'accuracy': accuracy_score(y_test, y_pred),\n",
    "                    'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "                    'recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "                    'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "                    'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "                    'cv_auc_mean': cv_scores.mean(),\n",
    "                    'cv_auc_std': cv_scores.std()\n",
    "                }\n",
    "                \n",
    "                task_results[name] = {\n",
    "                    'model': model,\n",
    "                    'metrics': metrics,\n",
    "                    'predictions': y_pred,\n",
    "                    'probabilities': y_pred_proba,\n",
    "                    'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "                }\n",
    "                \n",
    "                print(f\"      {name}: AUC={metrics['roc_auc']:.3f}, F1={metrics['f1']:.3f}\")\n",
    "                \n",
    "                if metrics['roc_auc'] > best_auc:\n",
    "                    best_auc = metrics['roc_auc']\n",
    "                    best_model_name = name\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"      {name}: FAILED - {e}\")\n",
    "        \n",
    "        # Store best model\n",
    "        if best_model_name:\n",
    "            self.best_models[task_key] = {\n",
    "                'name': best_model_name,\n",
    "                'model': task_results[best_model_name]['model'],\n",
    "                'metrics': task_results[best_model_name]['metrics'],\n",
    "                'features': features,\n",
    "                'split_info': self.split_info.get(target, {}),\n",
    "                'confusion_matrix': task_results[best_model_name]['confusion_matrix']\n",
    "            }\n",
    "            print(f\"      ✓ Best: {best_model_name} (AUC={best_auc:.3f})\")\n",
    "        \n",
    "        self.results[task_key] = task_results\n",
    "        \n",
    "        return task_results\n",
    "    \n",
    "    def train_all_tasks(self, split_method='temporal'):\n",
    "        \"\"\"Train models for all research questions\"\"\"\n",
    "        \n",
    "        print(f\"\\n  Training all models (split method: {split_method})...\")\n",
    "        \n",
    "        # Define tasks with appropriate targets\n",
    "        tasks = [\n",
    "            # Q1: First year struggle - can include active students who completed Y1\n",
    "            ('admission', 'first_year_struggle'),\n",
    "            \n",
    "            # Q2: AJC case - can include all students\n",
    "            ('admission', 'has_ajc_case'),\n",
    "            \n",
    "            # Q3-Q4: Major success/struggle with Y1 data - graduated only\n",
    "            ('year1', 'major_success'),\n",
    "            ('year1', 'major_struggle'),\n",
    "            \n",
    "            # Q9: Extended graduation - graduated only\n",
    "            ('year1', 'extended_graduation'),\n",
    "            \n",
    "            # NEW: Completion - non-active students\n",
    "            ('admission', 'completed_degree'),\n",
    "            \n",
    "            # NEW: Retention after Y1\n",
    "            ('admission', 'retained_after_y1'),\n",
    "        ]\n",
    "        \n",
    "        for feature_type, target in tasks:\n",
    "            if target in self.master_df.columns:\n",
    "                # Check if we have valid cases\n",
    "                valid_count = self.master_df[target].notna().sum()\n",
    "                if valid_count >= 50:\n",
    "                    self.train_task(feature_type, target, split_method=split_method)\n",
    "                else:\n",
    "                    print(f\"\\n    Skipping {target}: Only {valid_count} valid cases\")\n",
    "            else:\n",
    "                print(f\"\\n    Skipping {target}: Column not found\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def get_feature_importance(self, task_key):\n",
    "        \"\"\"Get feature importance from best model\"\"\"\n",
    "        \n",
    "        if task_key not in self.best_models:\n",
    "            return None\n",
    "        \n",
    "        model_info = self.best_models[task_key]\n",
    "        model = model_info['model']\n",
    "        features = model_info['features']\n",
    "        \n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            importance = np.abs(model.coef_[0])\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'feature': features,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get summary of all results\"\"\"\n",
    "        \n",
    "        summary = []\n",
    "        \n",
    "        for task_key, model_info in self.best_models.items():\n",
    "            metrics = model_info['metrics']\n",
    "            split_info = model_info.get('split_info', {})\n",
    "            \n",
    "            summary.append({\n",
    "                'Task': task_key,\n",
    "                'Best Model': model_info['name'],\n",
    "                'ROC AUC': round(metrics['roc_auc'], 3),\n",
    "                'Accuracy': round(metrics['accuracy'], 3),\n",
    "                'F1 Score': round(metrics['f1'], 3),\n",
    "                'CV AUC': f\"{metrics['cv_auc_mean']:.3f}±{metrics['cv_auc_std']:.3f}\",\n",
    "                'Split': split_info.get('method', 'unknown'),\n",
    "                'Train Size': split_info.get('train_size', 'N/A'),\n",
    "                'Test Size': split_info.get('test_size', split_info.get('test_size_actual', 'N/A'))\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(summary)\n",
    "    \n",
    "    def save_models(self, output_dir='models/'):\n",
    "        \"\"\"Save trained models\"\"\"\n",
    "        \n",
    "        import joblib\n",
    "        import json\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        for task_key, model_info in self.best_models.items():\n",
    "            # Save model\n",
    "            model_path = f\"{output_dir}{task_key}_model.joblib\"\n",
    "            joblib.dump(model_info['model'], model_path)\n",
    "            \n",
    "            # Save scaler if exists\n",
    "            for scaler_key, scaler in self.scalers.items():\n",
    "                if task_key.split('_')[-1] in scaler_key:\n",
    "                    scaler_path = f\"{output_dir}{task_key}_scaler.joblib\"\n",
    "                    joblib.dump(scaler, scaler_path)\n",
    "                    break\n",
    "            \n",
    "            # Save features\n",
    "            features_path = f\"{output_dir}{task_key}_features.json\"\n",
    "            with open(features_path, 'w') as f:\n",
    "                json.dump(model_info['features'], f)\n",
    "            \n",
    "            # Save split info\n",
    "            split_path = f\"{output_dir}{task_key}_split_info.json\"\n",
    "            with open(split_path, 'w') as f:\n",
    "                # Convert any numpy types to native Python types\n",
    "                split_info = model_info.get('split_info', {})\n",
    "                split_info_clean = {}\n",
    "                for k, v in split_info.items():\n",
    "                    if isinstance(v, (np.integer, np.floating)):\n",
    "                        split_info_clean[k] = float(v)\n",
    "                    elif isinstance(v, np.ndarray):\n",
    "                        split_info_clean[k] = v.tolist()\n",
    "                    elif isinstance(v, list):\n",
    "                        split_info_clean[k] = [float(x) if isinstance(x, (np.integer, np.floating)) else x for x in v]\n",
    "                    else:\n",
    "                        split_info_clean[k] = v\n",
    "                json.dump(split_info_clean, f)\n",
    "            \n",
    "            print(f\"    Saved: {task_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf36e3dd-3c98-4ded-aabf-fdd005575e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PHASE 7] MODEL TRAINING\n",
      "--------------------------------------------------\n",
      "\n",
      "  Training all models (split method: temporal)...\n",
      "\n",
      "    Training: admission_first_year_struggle (split: temporal)\n",
      "      Valid samples for 'first_year_struggle': 2344\n",
      "      Using 17 features\n",
      "      Available years: [2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0, 2028.0]\n",
      "      Train years: [2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0]\n",
      "      Test years: [2028.0]\n",
      "      Split: Train=1971 ([2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0]), Test=373 ([2028.0])\n",
      "      Train class dist: {0: 1786, 1: 185}\n",
      "      Test class dist: {0: 340, 1: 33}\n",
      "      Applying SMOTE (ratio: 0.10)\n",
      "      After SMOTE: 3572 samples\n",
      "      Logistic Regression: AUC=0.611, F1=0.222\n",
      "      Random Forest: AUC=0.636, F1=0.302\n",
      "      Gradient Boosting: AUC=0.665, F1=0.226\n",
      "      ✓ Best: Gradient Boosting (AUC=0.665)\n",
      "\n",
      "    Training: admission_has_ajc_case (split: temporal)\n",
      "      Valid samples for 'has_ajc_case': 12647\n",
      "      Using 17 features\n",
      "      Available years: [2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0, 2028.0]\n",
      "      Train years: [2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0]\n",
      "      Test years: [2028.0]\n",
      "      Split: Train=12274 ([2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0]), Test=373 ([2028.0])\n",
      "      Train class dist: {0: 12179, 1: 95}\n",
      "      Test class dist: {0: 371, 1: 2}\n",
      "      Applying SMOTE (ratio: 0.01)\n",
      "      After SMOTE: 24358 samples\n",
      "      Logistic Regression: AUC=0.523, F1=0.007\n",
      "      Random Forest: AUC=0.162, F1=0.000\n",
      "      Gradient Boosting: AUC=0.340, F1=0.000\n",
      "      ✓ Best: Logistic Regression (AUC=0.523)\n",
      "\n",
      "    Training: year1_major_success (split: temporal)\n",
      "      Valid samples for 'major_success': 1140\n",
      "      Using 17 features\n",
      "      Available years: [2022.0, 2023.0, 2024.0, 2025.0]\n",
      "      Train years: [2022.0, 2023.0, 2024.0]\n",
      "      Test years: [2025.0]\n",
      "      Split: Train=906 ([2022.0, 2023.0, 2024.0]), Test=234 ([2025.0])\n",
      "      Train class dist: {1: 576, 0: 330}\n",
      "      Test class dist: {1: 153, 0: 81}\n",
      "      Logistic Regression: AUC=0.727, F1=0.739\n",
      "      Random Forest: AUC=0.710, F1=0.750\n",
      "      Gradient Boosting: AUC=0.699, F1=0.752\n",
      "      ✓ Best: Logistic Regression (AUC=0.727)\n",
      "\n",
      "    Training: year1_major_struggle (split: temporal)\n",
      "      Valid samples for 'major_struggle': 1140\n",
      "      Using 17 features\n",
      "      Available years: [2022.0, 2023.0, 2024.0, 2025.0]\n",
      "      Train years: [2022.0, 2023.0, 2024.0]\n",
      "      Test years: [2025.0]\n",
      "      Split: Train=906 ([2022.0, 2023.0, 2024.0]), Test=234 ([2025.0])\n",
      "      Train class dist: {0: 906}\n",
      "      Test class dist: {0: 234}\n",
      "      Logistic Regression: FAILED - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ml-data-science/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/ml-data-science/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ml-data-science/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1335, in fit\n",
      "    raise ValueError(\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "      Random Forest: FAILED - index 1 is out of bounds for axis 1 with size 1\n",
      "      Gradient Boosting: FAILED - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ml-data-science/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/ml-data-science/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ml-data-science/lib/python3.12/site-packages/sklearn/ensemble/_gb.py\", line 669, in fit\n",
      "    y = self._encode_y(y=y, sample_weight=None)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ml-data-science/lib/python3.12/site-packages/sklearn/ensemble/_gb.py\", line 1536, in _encode_y\n",
      "    raise ValueError(\n",
      "ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "\n",
      "\n",
      "    Training: year1_extended_graduation (split: temporal)\n",
      "      Valid samples for 'extended_graduation': 1140\n",
      "      Using 17 features\n",
      "      Available years: [2022.0, 2023.0, 2024.0, 2025.0]\n",
      "      Train years: [2022.0, 2023.0, 2024.0]\n",
      "      Test years: [2025.0]\n",
      "      Split: Train=906 ([2022.0, 2023.0, 2024.0]), Test=234 ([2025.0])\n",
      "      Train class dist: {0: 533, 1: 373}\n",
      "      Test class dist: {0: 234}\n",
      "      Logistic Regression: AUC=nan, F1=0.000\n",
      "      Random Forest: AUC=nan, F1=0.000\n",
      "      Gradient Boosting: AUC=nan, F1=0.000\n",
      "\n",
      "    Training: admission_completed_degree (split: temporal)\n",
      "      Valid samples for 'completed_degree': 11588\n",
      "      Using 17 features\n",
      "      Available years: [2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0, 2028.0]\n",
      "      Train years: [2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0]\n",
      "      Test years: [2028.0]\n",
      "    ⚠️ Insufficient data for temporal split, falling back to random\n",
      "      Class distribution: {0: 10448, 1: 1140}\n",
      "      Split: Train=9270, Test=2318\n",
      "      Applying SMOTE (ratio: 0.11)\n",
      "      After SMOTE: 16716 samples\n",
      "      Logistic Regression: AUC=0.905, F1=0.689\n",
      "      Random Forest: AUC=0.885, F1=0.609\n",
      "      Gradient Boosting: AUC=0.901, F1=0.732\n",
      "      ✓ Best: Logistic Regression (AUC=0.905)\n",
      "\n",
      "    Training: admission_retained_after_y1 (split: temporal)\n",
      "      Valid samples for 'retained_after_y1': 2344\n",
      "      Using 17 features\n",
      "      Available years: [2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0, 2028.0]\n",
      "      Train years: [2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0]\n",
      "      Test years: [2028.0]\n",
      "      Split: Train=1971 ([2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0]), Test=373 ([2028.0])\n",
      "      Train class dist: {1: 1928, 0: 43}\n",
      "      Test class dist: {1: 372, 0: 1}\n",
      "      Applying SMOTE (ratio: 0.02)\n",
      "      After SMOTE: 3856 samples\n",
      "      Logistic Regression: AUC=0.429, F1=0.797\n",
      "      Random Forest: AUC=0.321, F1=0.993\n",
      "      Gradient Boosting: AUC=0.515, F1=0.997\n",
      "      ✓ Best: Gradient Boosting (AUC=0.515)\n",
      "\n",
      "  Model Performance Summary:\n",
      "                         Task          Best Model  ROC AUC  Accuracy  F1 Score      CV AUC    Split  Train Size  Test Size\n",
      "admission_first_year_struggle   Gradient Boosting    0.665     0.890     0.226 0.956±0.003 temporal        3572      373.0\n",
      "       admission_has_ajc_case Logistic Regression    0.523     0.257     0.007 0.864±0.004 temporal       24358      373.0\n",
      "          year1_major_success Logistic Regression    0.727     0.679     0.739 0.677±0.005 temporal         906      234.0\n",
      "   admission_completed_degree Logistic Regression    0.905     0.936     0.689 0.909±0.004   random       16716        0.2\n",
      "  admission_retained_after_y1   Gradient Boosting    0.515     0.995     0.997 0.994±0.002 temporal        3856      373.0\n",
      "\n",
      "  Saving models...\n",
      "    Saved: admission_first_year_struggle\n",
      "    Saved: admission_has_ajc_case\n",
      "    Saved: year1_major_success\n",
      "    Saved: admission_completed_degree\n",
      "    Saved: admission_retained_after_y1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[PHASE 7] MODEL TRAINING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "trainer = ModelTrainer(master_df, feature_sets, semester_records)\n",
    "trainer.train_all_tasks(split_method='temporal')\n",
    "\n",
    "if trainer.best_models:\n",
    "    print(\"\\n  Model Performance Summary:\")\n",
    "    print(trainer.get_summary().to_string(index=False))\n",
    "    \n",
    "    print(\"\\n  Saving models...\")\n",
    "    trainer.save_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195a7f3-784c-46a3-bd4e-7153f415709d",
   "metadata": {},
   "source": [
    "#### Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1d05b28-195e-40bb-a092-7a391c8613bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu, kruskal\n",
    "\n",
    "class StatisticalAnalyzer:\n",
    "    \"\"\"Statistical tests for research questions\"\"\"\n",
    "    \n",
    "    def __init__(self, master_df, semester_records):\n",
    "        self.master_df = master_df.copy()\n",
    "        self.semester_records = semester_records.copy() if semester_records is not None else pd.DataFrame()\n",
    "        self.results = {}\n",
    "    \n",
    "    def run_all_analyses(self):\n",
    "        \"\"\"Run all statistical analyses\"\"\"\n",
    "        \n",
    "        print(\"\\n  Running statistical analyses...\")\n",
    "        \n",
    "        self._analyze_math_track()      # Q7\n",
    "        self._analyze_cs_college_algebra()  # Q8\n",
    "        self._analyze_risk_factors()\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def _analyze_math_track(self):\n",
    "        \"\"\"Q7: Compare performance across math tracks\"\"\"\n",
    "        \n",
    "        if 'math_track' not in self.master_df.columns:\n",
    "            print(\"    ✗ Math track data not available\")\n",
    "            return\n",
    "        \n",
    "        df = self.master_df[\n",
    "            (self.master_df['math_track'].notna()) & \n",
    "            (self.master_df['math_track'] != 'Unknown') &\n",
    "            (self.master_df['final_cgpa'].notna())\n",
    "        ]\n",
    "        \n",
    "        if len(df) < 30:\n",
    "            print(\"    ✗ Insufficient data for math track analysis\")\n",
    "            return\n",
    "        \n",
    "        print(\"    Q7: Math Track Analysis\")\n",
    "        \n",
    "        # Summary stats\n",
    "        summary = df.groupby('math_track').agg({\n",
    "            'final_cgpa': ['count', 'mean', 'std', 'median'],\n",
    "            'total_semesters': 'mean' if 'total_semesters' in df.columns else 'count',\n",
    "            'first_year_struggle': 'mean' if 'first_year_struggle' in df.columns else 'count'\n",
    "        })\n",
    "        \n",
    "        print(f\"       Summary:\\n{summary}\")\n",
    "        \n",
    "        # Kruskal-Wallis test\n",
    "        tracks = df['math_track'].unique()\n",
    "        groups = [df[df['math_track'] == t]['final_cgpa'].dropna() for t in tracks]\n",
    "        groups = [g for g in groups if len(g) >= 5]\n",
    "        \n",
    "        if len(groups) >= 2:\n",
    "            stat, p_value = kruskal(*groups)\n",
    "            print(f\"       Kruskal-Wallis: H={stat:.3f}, p={p_value:.4f}\")\n",
    "            print(f\"       Significant difference: {'YES' if p_value < 0.05 else 'NO'}\")\n",
    "            \n",
    "            self.results['math_track'] = {\n",
    "                'summary': summary,\n",
    "                'kruskal_h': stat,\n",
    "                'p_value': p_value,\n",
    "                'significant': p_value < 0.05\n",
    "            }\n",
    "    \n",
    "    def _analyze_cs_college_algebra(self):\n",
    "        \"\"\"Q8: Can College Algebra students succeed in CS?\"\"\"\n",
    "        \n",
    "        if 'is_cs_major' not in self.master_df.columns:\n",
    "            # Try to identify CS students\n",
    "            if 'final_program' in self.master_df.columns:\n",
    "                self.master_df['is_cs_major'] = self.master_df['final_program'].str.contains(\n",
    "                    'Computer', case=False, na=False\n",
    "                ).astype(int)\n",
    "            else:\n",
    "                print(\"    ✗ Cannot identify CS majors\")\n",
    "                return\n",
    "        \n",
    "        cs_df = self.master_df[self.master_df['is_cs_major'] == 1]\n",
    "        \n",
    "        if len(cs_df) < 10:\n",
    "            print(\"    ✗ Insufficient CS students for analysis\")\n",
    "            return\n",
    "        \n",
    "        print(f\"    Q8: CS + College Algebra Analysis (n={len(cs_df)})\")\n",
    "        \n",
    "        if 'math_track' not in cs_df.columns or cs_df['math_track'].isna().all():\n",
    "            print(\"       ✗ Math track not available for CS students\")\n",
    "            return\n",
    "        \n",
    "        # Summary by math track\n",
    "        cs_summary = cs_df.groupby('math_track').agg({\n",
    "            'student_id': 'count',\n",
    "            'final_cgpa': 'mean',\n",
    "            'major_success': 'mean' if 'major_success' in cs_df.columns else 'count'\n",
    "        })\n",
    "        cs_summary.columns = ['Count', 'Avg CGPA', 'Success Rate']\n",
    "        \n",
    "        print(f\"       {cs_summary}\")\n",
    "        \n",
    "        # Specific analysis for College Algebra in CS\n",
    "        ca_cs = cs_df[cs_df['math_track'] == 'College Algebra']\n",
    "        other_cs = cs_df[cs_df['math_track'] != 'College Algebra']\n",
    "        \n",
    "        if len(ca_cs) >= 5 and len(other_cs) >= 5:\n",
    "            # Mann-Whitney U test\n",
    "            stat, p = mannwhitneyu(\n",
    "                ca_cs['final_cgpa'].dropna(),\n",
    "                other_cs['final_cgpa'].dropna(),\n",
    "                alternative='two-sided'\n",
    "            )\n",
    "            \n",
    "            ca_success = ca_cs['major_success'].mean() if 'major_success' in ca_cs.columns else 'N/A'\n",
    "            \n",
    "            print(f\"       College Algebra in CS: n={len(ca_cs)}, Success Rate={ca_success:.1%}\" if isinstance(ca_success, float) else f\"       College Algebra in CS: n={len(ca_cs)}\")\n",
    "            print(f\"       Mann-Whitney U: p={p:.4f}\")\n",
    "            \n",
    "            self.results['cs_college_algebra'] = {\n",
    "                'summary': cs_summary,\n",
    "                'ca_count': len(ca_cs),\n",
    "                'ca_success_rate': ca_success if isinstance(ca_success, float) else None,\n",
    "                'mann_whitney_p': p\n",
    "            }\n",
    "    \n",
    "    def _analyze_risk_factors(self):\n",
    "        \"\"\"Analyze key risk factors\"\"\"\n",
    "        \n",
    "        print(\"    Risk Factor Analysis\")\n",
    "        \n",
    "        target_col = 'first_year_struggle'\n",
    "        \n",
    "        if target_col not in self.master_df.columns:\n",
    "            return\n",
    "        \n",
    "        # Categorical factors\n",
    "        cat_factors = ['Gender', 'math_track', 'exam_source', 'performance_tier']\n",
    "        \n",
    "        for factor in cat_factors:\n",
    "            if factor in self.master_df.columns:\n",
    "                try:\n",
    "                    contingency = pd.crosstab(\n",
    "                        self.master_df[factor], \n",
    "                        self.master_df[target_col]\n",
    "                    )\n",
    "                    \n",
    "                    if contingency.shape[0] >= 2 and contingency.shape[1] >= 2:\n",
    "                        chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "                        print(f\"       {factor}: χ²={chi2:.2f}, p={p:.4f}\")\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate text report\"\"\"\n",
    "        \n",
    "        lines = [\n",
    "            \"=\" * 60,\n",
    "            \"STATISTICAL ANALYSIS REPORT\",\n",
    "            \"=\" * 60,\n",
    "            \"\"\n",
    "        ]\n",
    "        \n",
    "        if 'math_track' in self.results:\n",
    "            r = self.results['math_track']\n",
    "            lines.extend([\n",
    "                \"Q7: MATH TRACK PERFORMANCE\",\n",
    "                \"-\" * 40,\n",
    "                f\"Kruskal-Wallis H: {r['kruskal_h']:.3f}\",\n",
    "                f\"p-value: {r['p_value']:.4f}\",\n",
    "                f\"Significant: {'Yes' if r['significant'] else 'No'}\",\n",
    "                \"\"\n",
    "            ])\n",
    "        \n",
    "        if 'cs_college_algebra' in self.results:\n",
    "            r = self.results['cs_college_algebra']\n",
    "            lines.extend([\n",
    "                \"Q8: CS + COLLEGE ALGEBRA\",\n",
    "                \"-\" * 40,\n",
    "                f\"College Algebra CS students: {r['ca_count']}\",\n",
    "                f\"Success rate: {r['ca_success_rate']:.1%}\" if r['ca_success_rate'] else \"Success rate: N/A\",\n",
    "                f\"Mann-Whitney p-value: {r['mann_whitney_p']:.4f}\",\n",
    "                \"\"\n",
    "            ])\n",
    "        \n",
    "        return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ade99d4-bebc-48fb-ace6-075e484c5181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PHASE 8] STATISTICAL ANALYSIS\n",
      "--------------------------------------------------\n",
      "\n",
      "  Running statistical analyses...\n",
      "    Q7: Math Track Analysis\n",
      "       Summary:\n",
      "                final_cgpa                            total_semesters  \\\n",
      "                     count      mean       std median            mean   \n",
      "math_track                                                              \n",
      "Calculus              1021  3.024016  0.563792  3.090        6.383937   \n",
      "College Algebra      11446  3.053847  0.190621  3.060        7.852962   \n",
      "Pre-Calculus           180  2.692722  0.612313  2.745        6.288889   \n",
      "\n",
      "                first_year_struggle  \n",
      "                               mean  \n",
      "math_track                           \n",
      "Calculus                   0.080313  \n",
      "College Algebra            0.092738  \n",
      "Pre-Calculus               0.166667  \n",
      "       Kruskal-Wallis: H=258.695, p=0.0000\n",
      "       Significant difference: YES\n",
      "    Q8: CS + College Algebra Analysis (n=4938)\n",
      "                        Count  Avg CGPA  Success Rate\n",
      "math_track                                    \n",
      "Calculus           417  2.993501      0.581921\n",
      "College Algebra   4470  3.051221      0.637755\n",
      "Pre-Calculus        51  2.564706      0.214286\n",
      "       College Algebra in CS: n=4470, Success Rate=63.8%\n",
      "       Mann-Whitney U: p=0.0000\n",
      "    Risk Factor Analysis\n",
      "       Gender: χ²=7.12, p=0.0076\n",
      "       math_track: χ²=13.53, p=0.0012\n",
      "       exam_source: χ²=42.85, p=0.0000\n",
      "       performance_tier: χ²=38.85, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[PHASE 8] STATISTICAL ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "stats_analyzer = StatisticalAnalyzer(master_df, semester_records)\n",
    "stats_results = stats_analyzer.run_all_analyses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d039d-f289-4943-acaf-ab5adc7e4a8a",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9ae8fcc-a249-430e-ad9a-437190f44fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class EDAGenerator:\n",
    "    \"\"\"Generate EDA visualizations\"\"\"\n",
    "    \n",
    "    def __init__(self, master_df, output_dir='reports/figures/'):\n",
    "        self.master_df = master_df.copy()\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        sns.set_palette(\"husl\")\n",
    "    \n",
    "    def generate_all(self):\n",
    "        \"\"\"Generate all plots\"\"\"\n",
    "        \n",
    "        print(\"\\n  Generating visualizations...\")\n",
    "        \n",
    "        self._plot_distributions()\n",
    "        self._plot_performance()\n",
    "        self._plot_risk_factors()\n",
    "        self._plot_correlations()\n",
    "        \n",
    "        print(f\"    ✓ Saved to {self.output_dir}\")\n",
    "    \n",
    "    def _plot_distributions(self):\n",
    "        \"\"\"Plot target variable distributions\"\"\"\n",
    "        \n",
    "        targets = ['first_year_struggle', 'has_ajc_case', 'major_success', 'extended_graduation']\n",
    "        available = [t for t in targets if t in self.master_df.columns]\n",
    "        \n",
    "        if not available:\n",
    "            return\n",
    "        \n",
    "        n_plots = len(available)\n",
    "        fig, axes = plt.subplots(1, n_plots, figsize=(4*n_plots, 4))\n",
    "        \n",
    "        if n_plots == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for ax, target in zip(axes, available):\n",
    "            counts = self.master_df[target].value_counts()\n",
    "            colors = ['#27ae60', '#e74c3c']\n",
    "            ax.bar([str(i) for i in counts.index], counts.values, color=colors[:len(counts)])\n",
    "            ax.set_title(target.replace('_', ' ').title())\n",
    "            ax.set_xlabel('Value')\n",
    "            ax.set_ylabel('Count')\n",
    "            \n",
    "            # Add percentages\n",
    "            total = counts.sum()\n",
    "            for i, v in enumerate(counts.values):\n",
    "                ax.text(i, v + total*0.01, f'{v/total:.1%}', ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}target_distributions.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def _plot_performance(self):\n",
    "        \"\"\"Plot performance metrics\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # 1. CGPA distribution\n",
    "        if 'final_cgpa' in self.master_df.columns:\n",
    "            ax = axes[0, 0]\n",
    "            self.master_df['final_cgpa'].hist(bins=20, ax=ax, color='steelblue', edgecolor='white')\n",
    "            ax.axvline(x=2.0, color='red', linestyle='--', label='Probation (2.0)')\n",
    "            ax.axvline(x=3.0, color='orange', linestyle='--', label='Success (3.0)')\n",
    "            ax.axvline(x=3.5, color='green', linestyle='--', label=\"Dean's List (3.5)\")\n",
    "            ax.set_title('Final CGPA Distribution')\n",
    "            ax.set_xlabel('CGPA')\n",
    "            ax.legend()\n",
    "        \n",
    "        # 2. Performance by major\n",
    "        if 'final_program' in self.master_df.columns and 'final_cgpa' in self.master_df.columns:\n",
    "            ax = axes[0, 1]\n",
    "            major_perf = self.master_df.groupby('final_program')['final_cgpa'].agg(['mean', 'count'])\n",
    "            major_perf = major_perf[major_perf['count'] >= 10].sort_values('mean')\n",
    "            \n",
    "            if len(major_perf) > 0:\n",
    "                ax.barh(major_perf.index, major_perf['mean'], color='teal')\n",
    "                ax.axvline(x=3.0, color='green', linestyle='--')\n",
    "                ax.set_title('Average CGPA by Major')\n",
    "                ax.set_xlabel('CGPA')\n",
    "        \n",
    "        # 3. Math track performance\n",
    "        if 'math_track' in self.master_df.columns and 'final_cgpa' in self.master_df.columns:\n",
    "            ax = axes[1, 0]\n",
    "            df = self.master_df[self.master_df['math_track'] != 'Unknown']\n",
    "            if len(df) > 0:\n",
    "                df.boxplot(column='final_cgpa', by='math_track', ax=ax)\n",
    "                ax.axhline(y=2.0, color='red', linestyle='--')\n",
    "                ax.axhline(y=3.0, color='green', linestyle='--')\n",
    "                ax.set_title('CGPA by Math Track')\n",
    "                ax.set_xlabel('Math Track')\n",
    "                ax.set_ylabel('Final CGPA')\n",
    "                plt.suptitle('')\n",
    "        \n",
    "        # 4. Struggle rate by performance tier\n",
    "        if 'performance_tier' in self.master_df.columns and 'first_year_struggle' in self.master_df.columns:\n",
    "            ax = axes[1, 1]\n",
    "            tier_struggle = self.master_df.groupby('performance_tier')['first_year_struggle'].mean()\n",
    "            tier_order = ['Excellent', 'Good', 'Average', 'Below Average', 'At Risk']\n",
    "            tier_struggle = tier_struggle.reindex([t for t in tier_order if t in tier_struggle.index])\n",
    "            \n",
    "            if len(tier_struggle) > 0:\n",
    "                ax.bar(tier_struggle.index, tier_struggle.values, color='coral')\n",
    "                ax.set_title('First Year Struggle Rate by HS Performance')\n",
    "                ax.set_xlabel('High School Performance Tier')\n",
    "                ax.set_ylabel('Struggle Rate')\n",
    "                ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}performance_analysis.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def _plot_risk_factors(self):\n",
    "        \"\"\"Plot risk factor analysis\"\"\"\n",
    "        \n",
    "        if 'first_year_struggle' not in self.master_df.columns:\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # 1. By gender\n",
    "        if 'Gender' in self.master_df.columns:\n",
    "            ax = axes[0, 0]\n",
    "            gender_risk = self.master_df.groupby('Gender')['first_year_struggle'].mean()\n",
    "            ax.bar(gender_risk.index, gender_risk.values, color=['#3498db', '#e74c3c', '#95a5a6'])\n",
    "            ax.set_title('First Year Struggle Rate by Gender')\n",
    "            ax.set_ylabel('Struggle Rate')\n",
    "        \n",
    "        # 2. By financial aid need\n",
    "        if 'needs_financial_aid' in self.master_df.columns:\n",
    "            ax = axes[0, 1]\n",
    "            aid_risk = self.master_df.groupby('needs_financial_aid')['first_year_struggle'].mean()\n",
    "            ax.bar(['No Aid', 'Needs Aid'], aid_risk.values, color=['#2ecc71', '#e74c3c'])\n",
    "            ax.set_title('Struggle Rate by Financial Aid Need')\n",
    "            ax.set_ylabel('Struggle Rate')\n",
    "        \n",
    "        # 3. By exam type\n",
    "        if 'exam_source' in self.master_df.columns:\n",
    "            ax = axes[1, 0]\n",
    "            exam_risk = self.master_df.groupby('exam_source')['first_year_struggle'].mean()\n",
    "            exam_risk = exam_risk.sort_values()\n",
    "            ax.barh(exam_risk.index, exam_risk.values, color='steelblue')\n",
    "            ax.set_title('Struggle Rate by Exam Type')\n",
    "            ax.set_xlabel('Struggle Rate')\n",
    "        \n",
    "        # 4. By international status\n",
    "        if 'is_international' in self.master_df.columns:\n",
    "            ax = axes[1, 1]\n",
    "            intl_risk = self.master_df.groupby('is_international')['first_year_struggle'].mean()\n",
    "            ax.bar(['Domestic', 'International'], intl_risk.values, color=['#3498db', '#9b59b6'])\n",
    "            ax.set_title('Struggle Rate: Domestic vs International')\n",
    "            ax.set_ylabel('Struggle Rate')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}risk_factors.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def _plot_correlations(self):\n",
    "        \"\"\"Plot correlation matrix\"\"\"\n",
    "        \n",
    "        # Select numeric columns related to outcomes\n",
    "        numeric_cols = self.master_df.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        key_patterns = ['cgpa', 'gpa', 'score', 'struggle', 'success', 'ajc', 'probation', 'semester']\n",
    "        key_cols = [c for c in numeric_cols if any(p in c.lower() for p in key_patterns)]\n",
    "        \n",
    "        if len(key_cols) < 3:\n",
    "            return\n",
    "        \n",
    "        # Limit to top 15 columns\n",
    "        key_cols = key_cols[:15]\n",
    "        \n",
    "        corr = self.master_df[key_cols].corr()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "        sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r',\n",
    "                   center=0, ax=ax, square=True, linewidths=0.5)\n",
    "        ax.set_title('Correlation Matrix of Key Variables')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}correlations.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a05372a-9756-4eb5-8e8e-f35f9dd279a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PHASE 9] VISUALIZATION\n",
      "--------------------------------------------------\n",
      "\n",
      "  Generating visualizations...\n",
      "    ✓ Saved to reports/figures/\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[PHASE 9] VISUALIZATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "eda = EDAGenerator(master_df)\n",
    "eda.generate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a60fe68-0db6-441b-9502-f80cca737832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 10: REPORT GENERATION (CONTINUED)\n",
    "# ============================================================================\n",
    "\n",
    "class ReportGenerator:\n",
    "    \"\"\"Generate final reports\"\"\"\n",
    "    \n",
    "    def __init__(self, master_df, model_results, stats_results):\n",
    "        self.master_df = master_df\n",
    "        self.model_results = model_results or {}\n",
    "        self.stats_results = stats_results or {}\n",
    "    \n",
    "    def generate_executive_summary(self, output_path='reports/executive_summary.txt'):\n",
    "        \"\"\"Generate executive summary\"\"\"\n",
    "        \n",
    "        lines = [\n",
    "            \"=\" * 80,\n",
    "            \"ASHESI STUDENT SUCCESS PREDICTION\",\n",
    "            \"EXECUTIVE SUMMARY REPORT\",\n",
    "            f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "            \"=\" * 80,\n",
    "            \"\",\n",
    "            \"1. OVERVIEW\",\n",
    "            \"-\" * 40\n",
    "        ]\n",
    "        \n",
    "        # Data summary\n",
    "        if self.master_df is not None and len(self.master_df) > 0:\n",
    "            lines.append(f\"Total Students Analyzed: {len(self.master_df)}\")\n",
    "            \n",
    "            if 'first_year_struggle' in self.master_df.columns:\n",
    "                rate = self.master_df['first_year_struggle'].mean() * 100\n",
    "                lines.append(f\"First Year Struggle Rate: {rate:.1f}%\")\n",
    "            \n",
    "            if 'major_success' in self.master_df.columns:\n",
    "                rate = self.master_df['major_success'].mean() * 100\n",
    "                lines.append(f\"Major Success Rate: {rate:.1f}%\")\n",
    "            \n",
    "            if 'has_ajc_case' in self.master_df.columns:\n",
    "                rate = self.master_df['has_ajc_case'].mean() * 100\n",
    "                lines.append(f\"AJC Case Rate: {rate:.1f}%\")\n",
    "            \n",
    "            if 'extended_graduation' in self.master_df.columns:\n",
    "                rate = self.master_df['extended_graduation'].mean() * 100\n",
    "                lines.append(f\"Extended Graduation Rate: {rate:.1f}%\")\n",
    "        \n",
    "        lines.extend([\"\", \"2. MODEL PERFORMANCE\", \"-\" * 40])\n",
    "        \n",
    "        # Model results\n",
    "        if self.model_results:\n",
    "            for task, info in self.model_results.items():\n",
    "                if 'metrics' in info:\n",
    "                    m = info['metrics']\n",
    "                    lines.append(f\"\\n{task}:\")\n",
    "                    lines.append(f\"  Best Model: {info.get('name', 'N/A')}\")\n",
    "                    lines.append(f\"  ROC AUC: {m.get('roc_auc', 0):.3f}\")\n",
    "                    lines.append(f\"  Accuracy: {m.get('accuracy', 0):.3f}\")\n",
    "                    lines.append(f\"  F1 Score: {m.get('f1', 0):.3f}\")\n",
    "        else:\n",
    "            lines.append(\"  No model results available\")\n",
    "        \n",
    "        lines.extend([\"\", \"3. KEY FINDINGS\", \"-\" * 40])\n",
    "        \n",
    "        # Key findings based on analysis\n",
    "        findings = self._generate_key_findings()\n",
    "        for i, finding in enumerate(findings, 1):\n",
    "            lines.append(f\"  {i}. {finding}\")\n",
    "        \n",
    "        lines.extend([\"\", \"4. RESEARCH QUESTIONS ADDRESSED\", \"-\" * 40])\n",
    "        \n",
    "        # Research questions summary\n",
    "        questions = [\n",
    "            (\"Q1\", \"Predict first-year academic struggle\", \"admission_first_year_struggle\"),\n",
    "            (\"Q2\", \"Predict AJC cases\", \"admission_has_ajc_case\"),\n",
    "            (\"Q3\", \"Predict major success (Y1 data)\", \"year1_major_success\"),\n",
    "            (\"Q4\", \"Predict major struggle (Y1 data)\", \"year1_major_struggle\"),\n",
    "            (\"Q5\", \"Predict major success (Y1+Y2 data)\", \"year2_major_success\"),\n",
    "            (\"Q6\", \"Predict major struggle (Y1+Y2 data)\", \"year2_major_struggle\"),\n",
    "            (\"Q7\", \"Math track performance differences\", \"statistical_test\"),\n",
    "            (\"Q8\", \"College Algebra success in CS\", \"statistical_test\"),\n",
    "            (\"Q9\", \"Predict extended graduation\", \"year1_extended_graduation\")\n",
    "        ]\n",
    "        \n",
    "        for q_id, q_desc, task_key in questions:\n",
    "            if task_key in self.model_results:\n",
    "                auc = self.model_results[task_key]['metrics'].get('roc_auc', 0)\n",
    "                status = f\"✓ Achieved (AUC: {auc:.3f})\"\n",
    "            elif task_key == \"statistical_test\":\n",
    "                if q_id == \"Q7\" and 'math_track' in self.stats_results:\n",
    "                    p = self.stats_results['math_track'].get('p_value', 1)\n",
    "                    sig = \"Significant\" if p < 0.05 else \"Not significant\"\n",
    "                    status = f\"✓ Analyzed (p={p:.4f}, {sig})\"\n",
    "                elif q_id == \"Q8\" and 'cs_college_algebra' in self.stats_results:\n",
    "                    status = \"✓ Analyzed\"\n",
    "                else:\n",
    "                    status = \"○ Not analyzed\"\n",
    "            else:\n",
    "                status = \"○ Not trained\"\n",
    "            \n",
    "            lines.append(f\"  {q_id}: {q_desc}\")\n",
    "            lines.append(f\"      Status: {status}\")\n",
    "        \n",
    "        lines.extend([\"\", \"5. STATISTICAL ANALYSIS RESULTS\", \"-\" * 40])\n",
    "        \n",
    "        # Math track analysis (Q7)\n",
    "        if 'math_track' in self.stats_results:\n",
    "            r = self.stats_results['math_track']\n",
    "            lines.append(\"\\n  Q7: Math Track Performance Comparison\")\n",
    "            lines.append(f\"      Kruskal-Wallis H-statistic: {r.get('kruskal_h', 'N/A'):.3f}\")\n",
    "            lines.append(f\"      p-value: {r.get('p_value', 'N/A'):.4f}\")\n",
    "            lines.append(f\"      Conclusion: {'Significant difference exists' if r.get('significant') else 'No significant difference'}\")\n",
    "        \n",
    "        # CS + College Algebra analysis (Q8)\n",
    "        if 'cs_college_algebra' in self.stats_results:\n",
    "            r = self.stats_results['cs_college_algebra']\n",
    "            lines.append(\"\\n  Q8: College Algebra Track in Computer Science\")\n",
    "            lines.append(f\"      College Algebra CS students: {r.get('ca_count', 'N/A')}\")\n",
    "            if r.get('ca_success_rate') is not None:\n",
    "                lines.append(f\"      Success rate: {r['ca_success_rate']:.1%}\")\n",
    "            lines.append(f\"      Conclusion: College Algebra students {'CAN' if r.get('ca_success_rate', 0) >= 0.5 else 'face challenges to'} succeed in CS\")\n",
    "        \n",
    "        lines.extend([\"\", \"6. RECOMMENDATIONS\", \"-\" * 40])\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommendations = self._generate_recommendations()\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            lines.append(f\"  {i}. {rec}\")\n",
    "        \n",
    "        lines.extend([\"\", \"7. IMPLEMENTATION PRIORITIES\", \"-\" * 40])\n",
    "        \n",
    "        priorities = [\n",
    "            \"HIGH PRIORITY:\",\n",
    "            \"  • Deploy early warning system for incoming students\",\n",
    "            \"  • Implement first-semester intervention protocols\",\n",
    "            \"  • Create math track support programs\",\n",
    "            \"\",\n",
    "            \"MEDIUM PRIORITY:\",\n",
    "            \"  • Develop major-specific mentoring programs\",\n",
    "            \"  • Build academic integrity awareness campaigns\",\n",
    "            \"  • Enhance financial aid advising\",\n",
    "            \"\",\n",
    "            \"LOW PRIORITY (Long-term):\",\n",
    "            \"  • Integrate with student information system\",\n",
    "            \"  • Create personalized learning pathways\",\n",
    "            \"  • Build predictive analytics dashboard\"\n",
    "        ]\n",
    "        \n",
    "        lines.extend(priorities)\n",
    "        \n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            \"8. DATA QUALITY NOTES\",\n",
    "            \"-\" * 40\n",
    "        ])\n",
    "        \n",
    "        # Data quality summary\n",
    "        if self.master_df is not None and len(self.master_df) > 0:\n",
    "            total_cols = len(self.master_df.columns)\n",
    "            missing_pct = (self.master_df.isnull().sum().sum() / \n",
    "                          (len(self.master_df) * total_cols)) * 100\n",
    "            \n",
    "            lines.append(f\"  Total features: {total_cols}\")\n",
    "            lines.append(f\"  Overall missing data: {missing_pct:.1f}%\")\n",
    "            lines.append(f\"  Students with complete records: {len(self.master_df.dropna())}\")\n",
    "            \n",
    "            # Exam type distribution\n",
    "            if 'exam_source' in self.master_df.columns:\n",
    "                lines.append(\"\\n  Exam Type Distribution:\")\n",
    "                exam_dist = self.master_df['exam_source'].value_counts()\n",
    "                for exam, count in exam_dist.items():\n",
    "                    lines.append(f\"    • {exam}: {count} ({count/len(self.master_df)*100:.1f}%)\")\n",
    "        \n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            \"=\" * 80,\n",
    "            \"END OF EXECUTIVE SUMMARY\",\n",
    "            \"=\" * 80\n",
    "        ])\n",
    "        \n",
    "        # Write to file\n",
    "        report_text = \"\\n\".join(lines)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(report_text)\n",
    "        \n",
    "        print(f\"    ✓ Saved: {output_path}\")\n",
    "        \n",
    "        return report_text\n",
    "    \n",
    "    def _generate_key_findings(self):\n",
    "        \"\"\"Generate key findings based on analysis results\"\"\"\n",
    "        \n",
    "        findings = []\n",
    "        \n",
    "        # Finding 1: Early prediction capability\n",
    "        if 'admission_first_year_struggle' in self.model_results:\n",
    "            auc = self.model_results['admission_first_year_struggle']['metrics'].get('roc_auc', 0)\n",
    "            if auc > 0.7:\n",
    "                findings.append(\n",
    "                    f\"Early prediction of academic struggle is achievable with good accuracy \"\n",
    "                    f\"(ROC AUC: {auc:.3f}) using only admission data.\"\n",
    "                )\n",
    "            elif auc > 0.6:\n",
    "                findings.append(\n",
    "                    f\"Moderate prediction of first-year struggle is possible (ROC AUC: {auc:.3f}), \"\n",
    "                    f\"but additional features may improve accuracy.\"\n",
    "                )\n",
    "        \n",
    "        # Finding 2: Math track impact\n",
    "        if 'math_track' in self.stats_results:\n",
    "            if self.stats_results['math_track'].get('significant'):\n",
    "                findings.append(\n",
    "                    \"Math track placement significantly impacts academic performance. \"\n",
    "                    \"Students on different tracks show statistically different outcomes.\"\n",
    "                )\n",
    "        \n",
    "        # Finding 3: CS + College Algebra\n",
    "        if 'cs_college_algebra' in self.stats_results:\n",
    "            r = self.stats_results['cs_college_algebra']\n",
    "            if r.get('ca_success_rate') is not None:\n",
    "                if r['ca_success_rate'] >= 0.5:\n",
    "                    findings.append(\n",
    "                        f\"College Algebra students CAN succeed in Computer Science \"\n",
    "                        f\"(Success rate: {r['ca_success_rate']:.1%}), though additional support is recommended.\"\n",
    "                    )\n",
    "                else:\n",
    "                    findings.append(\n",
    "                        f\"College Algebra students face challenges in Computer Science \"\n",
    "                        f\"(Success rate: {r['ca_success_rate']:.1%}). Targeted support programs are needed.\"\n",
    "                    )\n",
    "        \n",
    "        # Finding 4: First semester importance\n",
    "        if self.master_df is not None and 'y1_GPA_mean' in self.master_df.columns:\n",
    "            findings.append(\n",
    "                \"First semester/year GPA is a strong predictor of overall academic success. \"\n",
    "                \"Early intervention during Year 1 is critical.\"\n",
    "            )\n",
    "        \n",
    "        # Finding 5: AJC prediction\n",
    "        if 'admission_has_ajc_case' in self.model_results:\n",
    "            auc = self.model_results['admission_has_ajc_case']['metrics'].get('roc_auc', 0)\n",
    "            findings.append(\n",
    "                f\"Academic misconduct risk can be partially predicted from admission data \"\n",
    "                f\"(ROC AUC: {auc:.3f}). Proactive integrity education is recommended.\"\n",
    "            )\n",
    "        \n",
    "        # Finding 6: Extended graduation\n",
    "        if 'year1_extended_graduation' in self.model_results:\n",
    "            auc = self.model_results['year1_extended_graduation']['metrics'].get('roc_auc', 0)\n",
    "            findings.append(\n",
    "                f\"Students at risk of extended graduation (>8 semesters) can be identified \"\n",
    "                f\"after Year 1 (ROC AUC: {auc:.3f}). Course planning support should be offered.\"\n",
    "            )\n",
    "        \n",
    "        # Default finding if none generated\n",
    "        if not findings:\n",
    "            findings.append(\n",
    "                \"Analysis completed. Further data collection and model refinement recommended.\"\n",
    "            )\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def _generate_recommendations(self):\n",
    "        \"\"\"Generate actionable recommendations\"\"\"\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # Recommendation 1: Early Warning System\n",
    "        if 'admission_first_year_struggle' in self.model_results:\n",
    "            auc = self.model_results['admission_first_year_struggle']['metrics'].get('roc_auc', 0)\n",
    "            if auc > 0.65:\n",
    "                recommendations.append(\n",
    "                    \"EARLY WARNING SYSTEM: Deploy the first-year struggle prediction model \"\n",
    "                    \"to identify at-risk students during admission. Flag students with >50% \"\n",
    "                    \"risk probability for immediate academic support enrollment.\"\n",
    "                )\n",
    "        \n",
    "        # Recommendation 2: Math Track Support\n",
    "        if 'math_track' in self.stats_results:\n",
    "            recommendations.append(\n",
    "                \"MATH SUPPORT PROGRAM: Create differentiated support programs for each math track. \"\n",
    "                \"College Algebra students pursuing quantitative majors (CS, Engineering, MIS) \"\n",
    "                \"should receive supplementary math tutoring and extended office hours.\"\n",
    "            )\n",
    "        \n",
    "        # Recommendation 3: First Semester Intervention\n",
    "        recommendations.append(\n",
    "            \"FIRST SEMESTER INTERVENTION: Implement mandatory check-ins for all students \"\n",
    "            \"after week 6 of first semester. Students with GPA < 2.5 should be enrolled \"\n",
    "            \"in academic success workshops and peer tutoring programs.\"\n",
    "        )\n",
    "        \n",
    "        # Recommendation 4: AJC Prevention\n",
    "        if 'admission_has_ajc_case' in self.model_results:\n",
    "            recommendations.append(\n",
    "                \"ACADEMIC INTEGRITY PROGRAM: Conduct proactive academic integrity workshops \"\n",
    "                \"during orientation. Students identified as higher risk should receive \"\n",
    "                \"additional ethics training and citation skills workshops.\"\n",
    "            )\n",
    "        \n",
    "        # Recommendation 5: Graduation Planning\n",
    "        recommendations.append(\n",
    "            \"GRADUATION TIMELINE ADVISING: Students predicted to need >8 semesters should \"\n",
    "            \"receive enhanced academic advising including optimized course sequencing, \"\n",
    "            \"summer course recommendations, and workload management support.\"\n",
    "        )\n",
    "        \n",
    "        # Recommendation 6: Major-Specific Support\n",
    "        recommendations.append(\n",
    "            \"MAJOR-SPECIFIC MENTORING: Pair at-risk students with successful upper-year \"\n",
    "            \"students in their intended major. Focus on majors with higher struggle rates.\"\n",
    "        )\n",
    "        \n",
    "        # Recommendation 7: Dashboard Deployment\n",
    "        recommendations.append(\n",
    "            \"ANALYTICS DASHBOARD: Deploy the interactive dashboard for admissions officers \"\n",
    "            \"and academic advisors to access real-time risk predictions and student insights.\"\n",
    "        )\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def generate_model_report(self, trainer, output_path='reports/model_report.txt'):\n",
    "        \"\"\"Generate detailed model performance report\"\"\"\n",
    "        \n",
    "        lines = [\n",
    "            \"=\" * 80,\n",
    "            \"PREDICTIVE MODEL PERFORMANCE REPORT\",\n",
    "            f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "            \"=\" * 80,\n",
    "            \"\"\n",
    "        ]\n",
    "        \n",
    "        for task_key, model_info in trainer.best_models.items():\n",
    "            lines.append(f\"\\n{'='*60}\")\n",
    "            lines.append(f\"TASK: {task_key}\")\n",
    "            lines.append(f\"{'='*60}\")\n",
    "            \n",
    "            lines.append(f\"\\nBest Model: {model_info['name']}\")\n",
    "            lines.append(f\"Features Used: {len(model_info['features'])}\")\n",
    "            \n",
    "            # Metrics\n",
    "            metrics = model_info['metrics']\n",
    "            lines.append(\"\\nPerformance Metrics:\")\n",
    "            lines.append(f\"  • ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "            lines.append(f\"  • Accuracy: {metrics['accuracy']:.4f}\")\n",
    "            lines.append(f\"  • Precision: {metrics['precision']:.4f}\")\n",
    "            lines.append(f\"  • Recall: {metrics['recall']:.4f}\")\n",
    "            lines.append(f\"  • F1 Score: {metrics['f1']:.4f}\")\n",
    "            lines.append(f\"  • CV AUC: {metrics['cv_auc_mean']:.4f} ± {metrics['cv_auc_std']:.4f}\")\n",
    "            \n",
    "            # Feature importance\n",
    "            importance = trainer.get_feature_importance(task_key)\n",
    "            if importance is not None and len(importance) > 0:\n",
    "                lines.append(\"\\nTop 10 Important Features:\")\n",
    "                for i, row in importance.head(10).iterrows():\n",
    "                    lines.append(f\"  {i+1}. {row['feature']}: {row['importance']:.4f}\")\n",
    "            \n",
    "            lines.append(\"\")\n",
    "        \n",
    "        # Write to file\n",
    "        report_text = \"\\n\".join(lines)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(report_text)\n",
    "        \n",
    "        print(f\"    ✓ Saved: {output_path}\")\n",
    "        \n",
    "        return report_text\n",
    "    \n",
    "    def generate_statistical_report(self, output_path='reports/statistical_report.txt'):\n",
    "        \"\"\"Generate statistical analysis report\"\"\"\n",
    "        \n",
    "        lines = [\n",
    "            \"=\" * 80,\n",
    "            \"STATISTICAL ANALYSIS REPORT\",\n",
    "            f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "            \"=\" * 80,\n",
    "            \"\"\n",
    "        ]\n",
    "        \n",
    "        # Q7: Math Track Analysis\n",
    "        lines.append(\"Q7: MATH TRACK PERFORMANCE COMPARISON\")\n",
    "        lines.append(\"-\" * 50)\n",
    "        \n",
    "        if 'math_track' in self.stats_results:\n",
    "            r = self.stats_results['math_track']\n",
    "            lines.append(f\"\\nStatistical Test: Kruskal-Wallis H-test\")\n",
    "            lines.append(f\"H-statistic: {r.get('kruskal_h', 'N/A'):.4f}\")\n",
    "            lines.append(f\"p-value: {r.get('p_value', 'N/A'):.6f}\")\n",
    "            lines.append(f\"Alpha level: 0.05\")\n",
    "            lines.append(f\"\\nConclusion: {'REJECT' if r.get('significant') else 'FAIL TO REJECT'} null hypothesis\")\n",
    "            \n",
    "            if r.get('significant'):\n",
    "                lines.append(\"Interpretation: There IS a statistically significant difference in \")\n",
    "                lines.append(\"academic performance across different math tracks.\")\n",
    "            else:\n",
    "                lines.append(\"Interpretation: There is NO statistically significant difference in \")\n",
    "                lines.append(\"academic performance across different math tracks.\")\n",
    "        else:\n",
    "            lines.append(\"Analysis not performed - insufficient data\")\n",
    "        \n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Q8: CS + College Algebra\n",
    "        lines.append(\"\\nQ8: COLLEGE ALGEBRA TRACK SUCCESS IN COMPUTER SCIENCE\")\n",
    "        lines.append(\"-\" * 50)\n",
    "        \n",
    "        if 'cs_college_algebra' in self.stats_results:\n",
    "            r = self.stats_results['cs_college_algebra']\n",
    "            lines.append(f\"\\nTotal CS Students Analyzed: {r.get('ca_count', 'N/A') + r.get('other_count', 0)}\")\n",
    "            lines.append(f\"College Algebra CS Students: {r.get('ca_count', 'N/A')}\")\n",
    "            \n",
    "            if r.get('ca_success_rate') is not None:\n",
    "                lines.append(f\"College Algebra Success Rate: {r['ca_success_rate']:.1%}\")\n",
    "            \n",
    "            if r.get('mann_whitney_p') is not None:\n",
    "                lines.append(f\"\\nMann-Whitney U Test p-value: {r['mann_whitney_p']:.6f}\")\n",
    "            \n",
    "            lines.append(\"\\nConclusion:\")\n",
    "            if r.get('ca_success_rate', 0) >= 0.5:\n",
    "                lines.append(\"  College Algebra students CAN succeed in Computer Science.\")\n",
    "                lines.append(\"  However, additional support is recommended to maximize success rates.\")\n",
    "            else:\n",
    "                lines.append(\"  College Algebra students face significant challenges in Computer Science.\")\n",
    "                lines.append(\"  Strong intervention programs are recommended for these students.\")\n",
    "        else:\n",
    "            lines.append(\"Analysis not performed - insufficient data\")\n",
    "        \n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Academic Policy Thresholds\n",
    "        lines.append(\"\\nACADEMIC POLICY REFERENCE\")\n",
    "        lines.append(\"-\" * 50)\n",
    "        lines.append(\"• Academic Probation: CGPA < 2.0 at end of any regular semester\")\n",
    "        lines.append(\"• Dismissal: Two consecutive semesters on probation without GPA ≥ 2.0\")\n",
    "        lines.append(\"• Dean's List: Semester GPA ≥ 3.5\")\n",
    "        lines.append(\"• Standard Graduation: 8 semesters (4 years)\")\n",
    "        \n",
    "        lines.append(\"\")\n",
    "        lines.append(\"=\" * 80)\n",
    "        \n",
    "        # Write to file\n",
    "        report_text = \"\\n\".join(lines)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(report_text)\n",
    "        \n",
    "        print(f\"    ✓ Saved: {output_path}\")\n",
    "        \n",
    "        return report_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "961f19db-3266-4125-9f6c-8da159a657f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PHASE 10] REPORT GENERATION\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[PHASE 10] REPORT GENERATION\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m reporter = ReportGenerator(master_df, \u001b[43mtrainer\u001b[49m.best_models, stats_results)\n\u001b[32m      5\u001b[39m reporter.generate_executive_summary()\n\u001b[32m      6\u001b[39m reporter.generate_model_report(trainer)\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n[PHASE 10] REPORT GENERATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "reporter = ReportGenerator(master_df, trainer.best_models, stats_results)\n",
    "reporter.generate_executive_summary()\n",
    "reporter.generate_model_report(trainer)\n",
    "reporter.generate_statistical_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e04b7c-1603-4245-a973-631707115a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
