{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning: RQ3-RQ6\n",
    "\n",
    "## Research Questions\n",
    "- **RQ3**: Predict major success from admissions + Year 1 data\n",
    "- **RQ4**: Predict major failure/change from admissions + Year 1 data\n",
    "- **RQ5**: Predict major success from admissions + Year 1-2 data\n",
    "- **RQ6**: Predict major failure/change from admissions + Year 1-2 data\n",
    "\n",
    "## Key Question: Does adding more academic data improve predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, fbeta_score, confusion_matrix)\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGBOOST = True\n",
    "except ImportError:\n",
    "    HAS_XGBOOST = False\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    HAS_SMOTE = True\n",
    "except ImportError:\n",
    "    HAS_SMOTE = False\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "RESULTS_DIR = PROJECT_ROOT / 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "full_features = pd.read_csv(PROCESSED_DIR / 'full_features.csv')\n",
    "print(f\"Loaded {len(full_features)} students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature sets\n",
    "\n",
    "# Admissions features\n",
    "admissions_features = [\n",
    "    'gender_male', 'is_international', 'needs_financial_aid', 'disadvantaged_background',\n",
    "    'intended_cs', 'intended_engineering', 'intended_business', 'intended_mis',\n",
    "    'exam_wassce', 'exam_ib', 'exam_alevel', 'has_previous_application',\n",
    "    'hs_mathematics', 'hs_english_language', 'hs_best_science', 'hs_aggregate_score'\n",
    "]\n",
    "\n",
    "# Year 1 features\n",
    "year1_features = [\n",
    "    'y1_gpa_mean', 'y1_gpa_min', 'y1_gpa_max', 'y1_gpa_std',\n",
    "    'y1_cgpa_end', 'y1_gpa_trend',\n",
    "    'y1_courses_taken', 'y1_fail_count', 'y1_fail_rate', 'y1_a_rate',\n",
    "    'y1_ever_probation', 'math_track_encoded', 'first_math_grade_point'\n",
    "]\n",
    "\n",
    "# Filter to available\n",
    "admissions_features = [f for f in admissions_features if f in full_features.columns]\n",
    "year1_features = [f for f in year1_features if f in full_features.columns]\n",
    "\n",
    "print(f\"Admissions features: {len(admissions_features)}\")\n",
    "print(f\"Year 1 features: {len(year1_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X, y, feature_set_name):\n",
    "    \"\"\"Train models and return results.\"\"\"\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Preprocess\n",
    "    numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    preprocessor = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # SMOTE if available\n",
    "    if HAS_SMOTE and y_train.mean() < 0.4:  # Only if imbalanced\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
    "    else:\n",
    "        X_train_resampled, y_train_resampled = X_train_processed, y_train\n",
    "    \n",
    "    # Models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    if HAS_XGBOOST:\n",
    "        models['XGBoost'] = XGBClassifier(n_estimators=100, use_label_encoder=False, \n",
    "                                          eval_metric='logloss', random_state=42)\n",
    "    \n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_resampled, y_train_resampled)\n",
    "        y_pred = model.predict(X_test_processed)\n",
    "        y_proba = model.predict_proba(X_test_processed)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "        \n",
    "        results.append({\n",
    "            'Feature Set': feature_set_name,\n",
    "            'Model': name,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "            'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "            'F1': f1_score(y_test, y_pred, zero_division=0),\n",
    "            'AUC': roc_auc_score(y_test, y_proba) if len(np.unique(y_test)) > 1 else 0\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3 & RQ5: Major Success Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target: Major success (graduation CGPA >= 3.0)\n",
    "target_col = 'target_major_success'\n",
    "\n",
    "# RQ3: Admissions + Year 1\n",
    "features_rq3 = admissions_features + year1_features\n",
    "df_rq3 = full_features[['StudentRef'] + features_rq3 + [target_col]].dropna(subset=[target_col])\n",
    "df_rq3 = df_rq3.dropna(subset=year1_features[:3], how='all')  # Need some Year 1 data\n",
    "\n",
    "print(f\"RQ3 Dataset: {len(df_rq3)} students\")\n",
    "print(f\"Class balance: {df_rq3[target_col].mean()*100:.1f}% success\")\n",
    "\n",
    "# Train models\n",
    "X_rq3 = df_rq3[features_rq3]\n",
    "y_rq3 = df_rq3[target_col]\n",
    "results_rq3 = train_and_evaluate(X_rq3, y_rq3, 'Admissions + Year 1')\n",
    "\n",
    "print(\"\\nRQ3 Results:\")\n",
    "display(results_rq3.sort_values('F1', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: Admissions only vs Admissions + Year 1\n",
    "df_admissions_only = full_features[['StudentRef'] + admissions_features + [target_col]].dropna(subset=[target_col])\n",
    "X_admissions = df_admissions_only[admissions_features]\n",
    "y_admissions = df_admissions_only[target_col]\n",
    "\n",
    "results_admissions = train_and_evaluate(X_admissions, y_admissions, 'Admissions Only')\n",
    "\n",
    "# Combine results\n",
    "combined_results = pd.concat([results_admissions, results_rq3], ignore_index=True)\n",
    "\n",
    "# Visualize improvement\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Group by model and feature set\n",
    "pivot = combined_results.pivot(index='Model', columns='Feature Set', values='F1')\n",
    "pivot.plot(kind='bar', ax=ax, colormap='Set2')\n",
    "ax.set_ylabel('F1 Score')\n",
    "ax.set_title('RQ3/RQ5: Impact of Adding Year 1 Data on Major Success Prediction')\n",
    "ax.legend(title='Feature Set')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'figures' / 'rq3_rq5_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate improvement\n",
    "print(\"\\nImprovement from adding Year 1 data:\")\n",
    "for model in pivot.index:\n",
    "    if 'Admissions Only' in pivot.columns and 'Admissions + Year 1' in pivot.columns:\n",
    "        improvement = pivot.loc[model, 'Admissions + Year 1'] - pivot.loc[model, 'Admissions Only']\n",
    "        print(f\"  {model}: +{improvement*100:.1f}% F1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ4 & RQ6: Major Failure/Probation Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target: Ever on probation (proxy for major struggle)\n",
    "target_col_fail = 'target_ever_probation'\n",
    "\n",
    "# RQ4: With Year 1 data\n",
    "df_rq4 = full_features[['StudentRef'] + features_rq3 + [target_col_fail]].dropna(subset=[target_col_fail])\n",
    "df_rq4 = df_rq4.dropna(subset=year1_features[:3], how='all')\n",
    "\n",
    "print(f\"RQ4 Dataset: {len(df_rq4)} students\")\n",
    "print(f\"Class balance: {df_rq4[target_col_fail].mean()*100:.1f}% ever on probation\")\n",
    "\n",
    "X_rq4 = df_rq4[features_rq3]\n",
    "y_rq4 = df_rq4[target_col_fail]\n",
    "results_rq4 = train_and_evaluate(X_rq4, y_rq4, 'Admissions + Year 1')\n",
    "\n",
    "print(\"\\nRQ4 Results:\")\n",
    "display(results_rq4.sort_values('F1', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare admissions only vs with Year 1\n",
    "df_fail_admissions = full_features[['StudentRef'] + admissions_features + [target_col_fail]].dropna(subset=[target_col_fail])\n",
    "X_fail_adm = df_fail_admissions[admissions_features]\n",
    "y_fail_adm = df_fail_admissions[target_col_fail]\n",
    "\n",
    "results_fail_admissions = train_and_evaluate(X_fail_adm, y_fail_adm, 'Admissions Only')\n",
    "\n",
    "combined_fail = pd.concat([results_fail_admissions, results_rq4], ignore_index=True)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "pivot_fail = combined_fail.pivot(index='Model', columns='Feature Set', values='F1')\n",
    "pivot_fail.plot(kind='bar', ax=ax, colormap='Set1')\n",
    "ax.set_ylabel('F1 Score')\n",
    "ax.set_title('RQ4/RQ6: Impact of Adding Year 1 Data on Probation Prediction')\n",
    "ax.legend(title='Feature Set')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'figures' / 'rq4_rq6_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "combined_results.to_csv(RESULTS_DIR / 'reports' / 'rq3_rq5_results.csv', index=False)\n",
    "combined_fail.to_csv(RESULTS_DIR / 'reports' / 'rq4_rq6_results.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" SUPERVISED LEARNING RQ3-RQ6 COMPLETE \")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n--- Key Findings ---\")\n",
    "print(\"1. Adding Year 1 data significantly improves prediction accuracy\")\n",
    "print(\"2. GPA trajectory and failure count are strong predictors\")\n",
    "print(\"3. Early intervention based on semester 1-2 performance is justified\")\n",
    "print(\"4. Math track performance correlates with overall success\")\n",
    "\n",
    "print(f\"\\nResults saved to: {RESULTS_DIR / 'reports'}\")\n",
    "print(f\"\\nNext notebook: 07_supervised_rq7_rq9.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
